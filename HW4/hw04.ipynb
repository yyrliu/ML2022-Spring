{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C_jdZ5vHJ4A9"
      },
      "source": [
        "# Task description\n",
        "- Classify the speakers of given features.\n",
        "- Main goal: Learn how to use transformer.\n",
        "- Baselines:\n",
        "  - Easy: Run sample code and know how to use transformer.\n",
        "  - Medium: Know how to adjust parameters of transformer.\n",
        "  - Strong: Construct [conformer](https://arxiv.org/abs/2005.08100) which is a variety of transformer. \n",
        "  - Boss: Implement [Self-Attention Pooling](https://arxiv.org/pdf/2008.01077v1.pdf) & [Additive Margin Softmax](https://arxiv.org/pdf/1801.05599.pdf) to further boost the performance.\n",
        "\n",
        "- Other links\n",
        "  - Kaggle: [link](https://www.kaggle.com/t/ac77388c90204a4c8daebeddd40ff916)\n",
        "  - Slide: [link](https://docs.google.com/presentation/d/1HLAj7UUIjZOycDe7DaVLSwJfXVd3bXPOyzSb6Zk3hYU/edit?usp=sharing)\n",
        "  - Data: [link](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)\n",
        "\n",
        "# Download dataset\n",
        "- Data is [here](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LhLNWB-AK2Z5"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partaa\n",
        "# !wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partab\n",
        "# !wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partac\n",
        "# !wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partad\n",
        "\n",
        "# !cat Dataset.tar.gz.part* > Dataset.tar.gz\n",
        "\n",
        "# unzip the file\n",
        "# !tar zxvf Dataset.tar.gz"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ENWVAUDVJtVY"
      },
      "source": [
        "## Fix Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E6burzCXIyuA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(87)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k7dVbxW2LASN"
      },
      "source": [
        "# Data\n",
        "\n",
        "## Dataset\n",
        "- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n",
        "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n",
        "- We randomly select 600 speakers from Voxceleb2.\n",
        "- Then preprocess the raw waveforms into mel-spectrograms.\n",
        "\n",
        "- Args:\n",
        "  - data_dir: The path to the data directory.\n",
        "  - metadata_path: The path to the metadata.\n",
        "  - segment_len: The length of audio segment for training. \n",
        "- The architecture of data directory \\\\\n",
        "  - data directory \\\\\n",
        "  |---- metadata.json \\\\\n",
        "  |---- testdata.json \\\\\n",
        "  |---- mapping.json \\\\\n",
        "  |---- uttr-{random string}.pt \\\\\n",
        "\n",
        "- The information in metadata\n",
        "  - \"n_mels\": The dimention of mel-spectrogram.\n",
        "  - \"speakers\": A dictionary. \n",
        "    - Key: speaker ids.\n",
        "    - value: \"feature_path\" and \"mel_len\"\n",
        "\n",
        "\n",
        "For efficiency, we segment the mel-spectrograms into segments in the traing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KpuGxl4CI2pr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        " \n",
        " \n",
        "class myDataset(Dataset):\n",
        "\tdef __init__(self, data_dir, segment_len=128):\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.segment_len = segment_len\n",
        "\t\n",
        "\t\t# Load the mapping from speaker neme to their corresponding id. \n",
        "\t\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\t\tmapping = json.load(mapping_path.open())\n",
        "\t\tself.speaker2id = mapping[\"speaker2id\"]\n",
        "\t\n",
        "\t\t# Load metadata of training data.\n",
        "\t\tmetadata_path = Path(data_dir) / \"metadata.json\"\n",
        "\t\tmetadata = json.load(open(metadata_path))[\"speakers\"]\n",
        "\t\n",
        "\t\t# Get the total number of speaker.\n",
        "\t\tself.speaker_num = len(metadata.keys())\n",
        "\t\tself.data = []\n",
        "\t\tfor speaker in metadata.keys():\n",
        "\t\t\tfor utterances in metadata[speaker]:\n",
        "\t\t\t\tself.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
        " \n",
        "\tdef __len__(self):\n",
        "\t\t\treturn len(self.data)\n",
        " \n",
        "\tdef __getitem__(self, index):\n",
        "\t\tfeat_path, speaker = self.data[index]\n",
        "\t\t# Load preprocessed mel-spectrogram.\n",
        "\t\tmel = torch.load(os.path.join(self.data_dir, \"uttrs\" ,feat_path))\n",
        "\n",
        "\t\t# Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "\t\tif len(mel) > self.segment_len:\n",
        "\t\t\t# Randomly get the starting point of the segment.\n",
        "\t\t\tstart = random.randint(0, len(mel) - self.segment_len)\n",
        "\t\t\t# Get a segment with \"segment_len\" frames.\n",
        "\t\t\tmel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "\t\telse:\n",
        "\t\t\tmel = torch.FloatTensor(mel)\n",
        "\t\t# Turn the speaker id into long for computing loss later.\n",
        "\t\tspeaker = torch.FloatTensor([speaker]).long()\n",
        "\t\treturn mel, speaker\n",
        " \n",
        "\tdef get_speaker_number(self):\n",
        "\t\treturn self.speaker_num"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "668hverTMlGN"
      },
      "source": [
        "## Dataloader\n",
        "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
        "- Create dataloader to iterate the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B7c2gZYoJDRS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "\t# Process features within a batch.\n",
        "\t\"\"\"Collate a batch of data.\"\"\"\n",
        "\tmel, speaker = zip(*batch)\n",
        "\t# Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
        "\tmel = pad_sequence(mel, batch_first=True, padding_value=1e-20)    # pad log 10^(-20) which is very small value.\n",
        "\t# mel: (batch size, length, 40)\n",
        "\treturn mel, torch.FloatTensor(speaker).long()\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size, n_workers, **kwargs):\n",
        "\t\"\"\"Generate dataloader\"\"\"\n",
        "\tdataset = myDataset(data_dir, **kwargs)\n",
        "\tspeaker_num = dataset.get_speaker_number()\n",
        "\t# Split dataset into training dataset and validation dataset\n",
        "\ttrainlen = int(0.9 * len(dataset))\n",
        "\tlengths = [trainlen, len(dataset) - trainlen]\n",
        "\ttrainset, validset = random_split(dataset, lengths)\n",
        "\n",
        "\ttrain_loader = DataLoader(\n",
        "\t\ttrainset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tshuffle=True,\n",
        "\t\tdrop_last=True,\n",
        "\t\tnum_workers=n_workers,\n",
        "\t\tpin_memory=True,\n",
        "\t\tcollate_fn=collate_batch,\n",
        "\t)\n",
        "\tvalid_loader = DataLoader(\n",
        "\t\tvalidset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tnum_workers=n_workers,\n",
        "\t\tdrop_last=True,\n",
        "\t\tpin_memory=True,\n",
        "\t\tcollate_fn=collate_batch,\n",
        "\t)\n",
        "\n",
        "\treturn train_loader, valid_loader, speaker_num"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5FOSZYxrMqhc"
      },
      "source": [
        "# Model\n",
        "- TransformerEncoderLayer:\n",
        "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "  - Parameters:\n",
        "    - d_model: the number of expected features of the input (required).\n",
        "\n",
        "    - nhead: the number of heads of the multiheadattention models (required).\n",
        "\n",
        "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "\n",
        "    - dropout: the dropout value (default=0.1).\n",
        "\n",
        "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "- TransformerEncoder:\n",
        "  - TransformerEncoder is a stack of N transformer encoder layers\n",
        "  - Parameters:\n",
        "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "\n",
        "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "\n",
        "    - norm: the layer normalization component (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iXZ5B0EKJGs8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier(\n",
            "  (prenet): Linear(in_features=40, out_features=80, bias=True)\n",
            "  (encoder_layer): TransformerEncoderLayer(\n",
            "    (self_attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
            "    )\n",
            "    (linear1): Linear(in_features=80, out_features=256, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear2): Linear(in_features=256, out_features=80, bias=True)\n",
            "    (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout1): Dropout(p=0.1, inplace=False)\n",
            "    (dropout2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=80, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=256, out_features=80, bias=True)\n",
            "        (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pred_layer): Sequential(\n",
            "    (0): Linear(in_features=80, out_features=600, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\tdef __init__(self, d_model=80, nhead=2, encoder_layers=1, n_spks=600, dropout=0.1):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# Project the dimension of features from that of input into d_model.\n",
        "\t\tself.prenet = nn.Linear(40, d_model)\n",
        "\t\t# TODO:\n",
        "\t\t#   Change Transformer to Conformer.\n",
        "\t\t#   https://arxiv.org/abs/2005.08100\n",
        "\t\tself.encoder_layer = nn.TransformerEncoderLayer(\n",
        "\t\t\td_model=d_model, dim_feedforward=256, nhead=nhead\n",
        "\t\t)\n",
        "\t\tself.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=encoder_layers)\n",
        "\n",
        "\t\t# Project the the dimension of features from d_model into speaker nums.\n",
        "\t\tself.pred_layer = nn.Sequential(\n",
        "\t\t\t# nn.Linear(d_model, d_model),\n",
        "\t\t\t# nn.ReLU(),\n",
        "\t\t\tnn.Linear(d_model, n_spks),\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, mels):\n",
        "\t\t\"\"\"\n",
        "\t\targs:\n",
        "\t\t\tmels: (batch size, length, 40)\n",
        "\t\treturn:\n",
        "\t\t\tout: (batch size, n_spks)\n",
        "\t\t\"\"\"\n",
        "\t\t# out: (batch size, length, d_model)\n",
        "\t\tout = self.prenet(mels)\n",
        "\t\t# out: (length, batch size, d_model)\n",
        "\t\tout = out.permute(1, 0, 2)\n",
        "\t\t# The encoder layer expect features in the shape of (length, batch size, d_model).\n",
        "\t\tout = self.encoder(out)\n",
        "\t\t# out: (batch size, length, d_model)\n",
        "\t\tout = out.transpose(0, 1)\n",
        "\t\t# mean pooling\n",
        "\t\tstats = out.mean(dim=1)\n",
        "\n",
        "\t\t# # max pooling\n",
        "\t\t# stats = torch.amax(out, dim=1)\n",
        "\n",
        "\t\t# out: (batch, n_spks)\n",
        "\t\tout = self.pred_layer(stats)\n",
        "\t\treturn out\n",
        "\t\n",
        "print(Classifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comformer Implementation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class Transpose(nn.Module):\n",
        "    \"\"\" Wrapper class of torch.transpose() for Sequential module. \"\"\"\n",
        "    def __init__(self, shape: tuple):\n",
        "        super(Transpose, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.transpose(*self.shape)\n",
        "\n",
        "class ResidualConnectionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Connection Module.\n",
        "    outputs = (module(inputs) x module_factor + inputs x input_factor)\n",
        "    \"\"\"\n",
        "    def __init__(self, module: nn.Module, module_factor: float = 1.0, input_factor: float = 1):\n",
        "        super(ResidualConnectionModule, self).__init__()\n",
        "        self.module = module\n",
        "        self.module_factor = module_factor\n",
        "        self.input_factor = input_factor\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return (self.module(inputs) * self.module_factor) + (inputs * self.input_factor)\n",
        "    \n",
        "class FeedForwardModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed Forward Module.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.sequential(inputs)\n",
        "    \n",
        "class ConvolutionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution Module.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, kernel_size: int = 31, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),          # (batch, length, d_model) -> (batch, length, d_model)\n",
        "            Transpose(shape=(1, 2)),        # (batch, length, d_model) -> (batch, d_model, length)\n",
        "            nn.Conv1d(d_model, d_model, kernel_size, padding=(kernel_size - 1) // 2),\n",
        "            # (batch, d_model, length) -> (batch, d_model, length)\n",
        "            nn.BatchNorm1d(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            Transpose(shape=(1, 2)),        #  (batch, d_model, length) -> (batch, length, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.sequential(inputs)\n",
        "\n",
        "class ComformerBlock(nn.Module):\n",
        "    def __init__(self, d_model=80, nhead=2, encoder_layers=1, n_spks=600, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feed_forward_1 = ResidualConnectionModule(\n",
        "            FeedForwardModule(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            module_factor=0.5\n",
        "        )\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=d_model, dim_feedforward=256, nhead=nhead, batch_first=True\n",
        "            ),\n",
        "            num_layers=encoder_layers\n",
        "        )\n",
        "\n",
        "        self.conv = ResidualConnectionModule(\n",
        "            ConvolutionModule(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.feed_forward_2 = ResidualConnectionModule(\n",
        "            FeedForwardModule(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            module_factor=0.5\n",
        "        )\n",
        "\n",
        "    def forward(self, mels):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            mels: (batch size, length, 40)\n",
        "        return:\n",
        "            out: (batch size, n_spks)\n",
        "        \"\"\"\n",
        "        # out: (batch size, length, d_model)\n",
        "        out = self.feed_forward_1(mels)\n",
        "        out = self.encoder(out)\n",
        "        out = self.conv(out)\n",
        "        out = self.feed_forward_2(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class SelfAttentionPooling(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of SelfAttentionPooling \n",
        "    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n",
        "    https://arxiv.org/pdf/2008.01077v1.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(SelfAttentionPooling, self).__init__()\n",
        "        # self.W = nn.Linear(input_dim, 1, bias=False)\n",
        "        self.W = torch.nn.Parameter(torch.empty(input_dim, 1), requires_grad=True)\n",
        "        torch.nn.init.xavier_uniform_(self.W)\n",
        "        \n",
        "    def forward(self, batch_rep):\n",
        "        \"\"\"\n",
        "        input:\n",
        "            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n",
        "        \n",
        "        attention_weight:\n",
        "            att_w : size (N, T, 1)\n",
        "        \n",
        "        return:\n",
        "            utter_rep: size (N, H)\n",
        "\n",
        "        \"\"\"\n",
        "        # att_w = nn.functional.softmax(self.W(batch_rep), dim=1)\n",
        "        att_w = nn.functional.softmax(batch_rep @ self.W, dim=1)\n",
        "        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n",
        "\n",
        "        return utter_rep\n",
        "\n",
        "\n",
        "class Comformer(nn.Module):\n",
        "    def __init__(self, d_model=80, nhead=2, comformer_layers=1, n_spks=600, dropout=0.1, pred_layer=True, norm_after_cf_block=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Project the dimension of features from that of input into d_model.\n",
        "        self.prenet = nn.Linear(40, d_model)\n",
        "\n",
        "        self.prenet_drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.layers = nn.ModuleList([ComformerBlock(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dropout=dropout,\n",
        "            n_spks=n_spks\n",
        "        ) for _ in range(comformer_layers)])\n",
        "\n",
        "        self.post_comformer_drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.self_attention_pooling = SelfAttentionPooling(d_model)\n",
        "\n",
        "        self.self_attention_pooling_drop = nn.Dropout(dropout)\n",
        "\n",
        "        if norm_after_cf_block:\n",
        "            self.layer_norm = nn.LayerNorm(d_model)\n",
        "        else:\n",
        "            self.layer_norm = nn.Identity()\n",
        "\n",
        "        if pred_layer:\n",
        "            self.pred_layer = nn.Sequential(\n",
        "                nn.Linear(d_model, d_model),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "        else:\n",
        "            self.pred_layer = nn.Identity()\n",
        "\n",
        "    def forward(self, mels):\n",
        "\n",
        "        out = self.prenet(mels)\n",
        "\n",
        "        out = self.prenet_drop(out)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "\n",
        "        out = self.post_comformer_drop(out)\n",
        "\n",
        "        out = self.layer_norm(out)\n",
        "\n",
        "        # mean pooling\n",
        "        # stats = out.mean(dim=1)\n",
        "\n",
        "        # self attention pooling\n",
        "        stats = self.self_attention_pooling(out)\n",
        "\n",
        "        stats = self.self_attention_pooling_drop(stats)\n",
        "\n",
        "        # out: (batch, n_spks)\n",
        "        out = self.pred_layer(stats)\n",
        "\n",
        "        return out\n",
        "\n",
        "# comformer = Comformer(d_model=240, nhead=6, encoder_layers=1, n_spks=600).to(\"cuda\")\n",
        "# print(summary(comformer, (128, 40)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comformer2 Implementation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class Transpose(nn.Module):\n",
        "    \"\"\" Wrapper class of torch.transpose() for Sequential module. \"\"\"\n",
        "    def __init__(self, shape: tuple):\n",
        "        super(Transpose, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.transpose(*self.shape)\n",
        "\n",
        "class ResidualConnectionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Connection Module.\n",
        "    outputs = (module(inputs) x module_factor + inputs x input_factor)\n",
        "    \"\"\"\n",
        "    def __init__(self, module: nn.Module, module_factor: float = 1.0, input_factor: float = 1):\n",
        "        super(ResidualConnectionModule, self).__init__()\n",
        "        self.module = module\n",
        "        self.module_factor = module_factor\n",
        "        self.input_factor = input_factor\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return (self.module(inputs) * self.module_factor) + (inputs * self.input_factor)\n",
        "    \n",
        "class FeedForwardModule2(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed Forward Module.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.sequential(inputs)\n",
        "    \n",
        "class ConvolutionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution Module.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, kernel_size: int = 31, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),          # (batch, length, d_model) -> (batch, length, d_model)\n",
        "            Transpose(shape=(1, 2)),        # (batch, length, d_model) -> (batch, d_model, length)\n",
        "            nn.Conv1d(d_model, d_model * 2, 1),\n",
        "            nn.GLU(1),\n",
        "            nn.Conv1d(d_model, d_model, kernel_size, padding=(kernel_size - 1) // 2, groups=d_model),\n",
        "            # (batch, d_model, length) -> (batch, d_model, length)\n",
        "            nn.BatchNorm1d(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(d_model, d_model, 1),\n",
        "            nn.Dropout(dropout),\n",
        "            Transpose(shape=(1, 2)),        #  (batch, d_model, length) -> (batch, length, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.sequential(inputs)\n",
        "\n",
        "class ComformerBlock2(nn.Module):\n",
        "    def __init__(self, d_model=80, nhead=2, encoder_layers=1, n_spks=600, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feed_forward_1 = ResidualConnectionModule(\n",
        "            FeedForwardModule2(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            module_factor=0.5\n",
        "        )\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=d_model, dim_feedforward=256, nhead=nhead, batch_first=True\n",
        "            ),\n",
        "            num_layers=encoder_layers\n",
        "        )\n",
        "\n",
        "        self.conv = ResidualConnectionModule(\n",
        "            ConvolutionModule(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.feed_forward_2 = ResidualConnectionModule(\n",
        "            FeedForwardModule2(\n",
        "                d_model=d_model,\n",
        "                dropout=dropout\n",
        "            ),\n",
        "            module_factor=0.5\n",
        "        )\n",
        "\n",
        "    def forward(self, mels):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            mels: (batch size, length, 40)\n",
        "        return:\n",
        "            out: (batch size, n_spks)\n",
        "        \"\"\"\n",
        "        # out: (batch size, length, d_model)\n",
        "        out = self.feed_forward_1(mels)\n",
        "        out = self.encoder(out)\n",
        "        out = self.conv(out)\n",
        "        out = self.feed_forward_2(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class SelfAttentionPooling(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of SelfAttentionPooling \n",
        "    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n",
        "    https://arxiv.org/pdf/2008.01077v1.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(SelfAttentionPooling, self).__init__()\n",
        "        # self.W = nn.Linear(input_dim, 1, bias=False)\n",
        "        self.W = torch.nn.Parameter(torch.empty(input_dim, 1), requires_grad=True)\n",
        "        torch.nn.init.xavier_uniform_(self.W)\n",
        "        \n",
        "    def forward(self, batch_rep):\n",
        "        \"\"\"\n",
        "        input:\n",
        "            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n",
        "        \n",
        "        attention_weight:\n",
        "            att_w : size (N, T, 1)\n",
        "        \n",
        "        return:\n",
        "            utter_rep: size (N, H)\n",
        "\n",
        "        \"\"\"\n",
        "        # att_w = nn.functional.softmax(self.W(batch_rep), dim=1)\n",
        "        att_w = nn.functional.softmax(batch_rep @ self.W, dim=1)\n",
        "        utter_rep = torch.mean(batch_rep * att_w, dim=1)\n",
        "\n",
        "        return utter_rep\n",
        "\n",
        "\n",
        "class Comformer2(nn.Module):\n",
        "    def __init__(self, d_model=80, nhead=2, comformer_layers=1, n_spks=600, dropout=0.1, pred_layer=0, norm_after_cf_block=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Project the dimension of features from that of input into d_model.\n",
        "        self.prenet = nn.Linear(40, d_model)\n",
        "\n",
        "        self.prenet_drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.layers = nn.ModuleList([ComformerBlock2(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dropout=dropout,\n",
        "            n_spks=n_spks\n",
        "        ) for _ in range(comformer_layers)])\n",
        "\n",
        "        self.post_comformer_drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.self_attention_pooling = SelfAttentionPooling(d_model)\n",
        "\n",
        "        self.self_attention_pooling_drop = nn.Dropout(dropout)\n",
        "\n",
        "        if norm_after_cf_block:\n",
        "            self.layer_norm = nn.LayerNorm(d_model)\n",
        "        else:\n",
        "            self.layer_norm = nn.Identity()\n",
        "\n",
        "        if pred_layer > 0:\n",
        "            self.pred_layers = nn.ModuleList([\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(d_model, d_model),\n",
        "                    nn.ReLU()\n",
        "                ) for _ in range(pred_layer)]\n",
        "            )\n",
        "        else:\n",
        "            self.pred_layers = nn.ModuleList([nn.Identity()])\n",
        "\n",
        "    def forward(self, mels):\n",
        "\n",
        "        out = self.prenet(mels)\n",
        "\n",
        "        out = self.prenet_drop(out)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "\n",
        "        out = self.post_comformer_drop(out)\n",
        "\n",
        "        out = self.layer_norm(out)\n",
        "\n",
        "        # mean pooling\n",
        "        # stats = out.mean(dim=1)\n",
        "\n",
        "        # self attention pooling\n",
        "        stats = self.self_attention_pooling(out)\n",
        "\n",
        "        stats = self.self_attention_pooling_drop(stats)\n",
        "\n",
        "        # out: (batch, n_spks)\n",
        "        for pred_layer in self.pred_layers:\n",
        "            stats = pred_layer(stats)\n",
        "            \n",
        "        return stats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from conformer import Conformer as RealComformer\n",
        "\n",
        "class RComformer(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.comformer = RealComformer(*args, **kwargs)\n",
        "        self.input_lengths = torch.full((32, ), 128, device=\"cuda\", dtype=torch.long)\n",
        "\n",
        "    def forward(self, mels):\n",
        "        out, _ = self.comformer(mels, self.input_lengths)\n",
        "        stats = out.mean(dim=1)\n",
        "\n",
        "        return stats"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yX8JinM5Ly"
      },
      "source": [
        "# Learning rate schedule\n",
        "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
        "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
        "- The warmup schedule\n",
        "  - Set learning rate to 0 in the beginning.\n",
        "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ykt0N1nVJJi2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tnum_training_steps: int,\n",
        "\tnum_cycles: float = 0.5,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\t\"\"\"\n",
        "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "\tinitial lr set in the optimizer.\n",
        "\n",
        "\tArgs:\n",
        "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
        "\t\tThe optimizer for which to schedule the learning rate.\n",
        "\t\tnum_warmup_steps (:obj:`int`):\n",
        "\t\tThe number of steps for the warmup phase.\n",
        "\t\tnum_training_steps (:obj:`int`):\n",
        "\t\tThe total number of training steps.\n",
        "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "\t\tfollowing a half-cosine).\n",
        "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "\t\tThe index of the last epoch when resuming training.\n",
        "\n",
        "\tReturn:\n",
        "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "\t\"\"\"\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "\t\t)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n",
        "def get_cosine_schedule(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_training_steps: int,\n",
        "\tnum_cycles: float = 0.5,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\t\"\"\"\n",
        "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "\tinitial lr set in the optimizer.\n",
        "\n",
        "\tArgs:\n",
        "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
        "\t\tThe optimizer for which to schedule the learning rate.\n",
        "\t\tnum_warmup_steps (:obj:`int`):\n",
        "\t\tThe number of steps for the warmup phase.\n",
        "\t\tnum_training_steps (:obj:`int`):\n",
        "\t\tThe total number of training steps.\n",
        "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "\t\tfollowing a half-cosine).\n",
        "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "\t\tThe index of the last epoch when resuming training.\n",
        "\n",
        "\tReturn:\n",
        "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "\t\"\"\"\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\tprogress = float(current_step) / float(\n",
        "\t\t\tmax(1, num_training_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "\t\t)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n",
        "def get_exp_schedule_with_warmup(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tnum_training_steps: int,\n",
        "\tdecay_const: float = 2.5,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\t\"\"\"\n",
        "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "\tinitial lr set in the optimizer.\n",
        "\n",
        "\tArgs:\n",
        "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
        "\t\tThe optimizer for which to schedule the learning rate.\n",
        "\t\tnum_warmup_steps (:obj:`int`):\n",
        "\t\tThe number of steps for the warmup phase.\n",
        "\t\tnum_training_steps (:obj:`int`):\n",
        "\t\tThe total number of training steps.\n",
        "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "\t\tfollowing a half-cosine).\n",
        "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "\t\tThe index of the last epoch when resuming training.\n",
        "\n",
        "\tReturn:\n",
        "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "\t\"\"\"\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, math.exp(-decay_const * progress)\n",
        "\t\t)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n",
        "def get_transformer_scheduler(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\tstep = current_step + 1\n",
        "\t\treturn min(step**(-0.5), step * num_warmup_steps**(-1.5)) / num_warmup_steps**(-0.5)\n",
        "\t\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\t\n",
        "def get_transformer_milestone_scheduler(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tswitch_to_milestone_steps: int,\n",
        "\tmilestones: int = 5000,\n",
        "\tmilestone_decay_rate: float = 0.7,\n",
        "\tmin_lr: float = 0.01,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\tif current_step < switch_to_milestone_steps:\n",
        "\t\t\tstep = current_step + 1\n",
        "\t\t\treturn min(step**(-0.5), step * num_warmup_steps**(-1.5)) / num_warmup_steps**(-0.5)\n",
        "\t\telse:\n",
        "\t\t\treturn max(switch_to_milestone_steps**(-0.5) / num_warmup_steps**(-0.5) * (milestone_decay_rate ** ((current_step - switch_to_milestone_steps) // milestones + 1)), min_lr)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_warmup_steps = 1000\n",
        "num_training_steps = 70000\n",
        "decay_const = 2.5\n",
        "\n",
        "def lr_lambda_exp(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, math.exp(-decay_const * progress)\n",
        "\t\t)\n",
        "\n",
        "num_cycles = 0.425\n",
        "\n",
        "def lr_lambda_sin(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "\t\t)\n",
        "\n",
        "switch_to_milestone_steps = 40000\n",
        "milestones = 1000\n",
        "milestone_decay_rate = 0.7\n",
        "\n",
        "def transform_lr(current_step):\n",
        "\tif current_step < switch_to_milestone_steps:\n",
        "\t\tstep = current_step + 1\n",
        "\t\treturn min(step**(-0.5), step * num_warmup_steps**(-1.5)) / num_warmup_steps**(-0.5)\n",
        "\telse:\n",
        "\t\treturn max(switch_to_milestone_steps**(-0.5) / num_warmup_steps**(-0.5) * (milestone_decay_rate ** ((current_step - switch_to_milestone_steps) // milestones + 1)), 0.01)\n",
        "\n",
        "x = [i for i in range(70000)]\n",
        "y1 = [lr_lambda_exp(i) for i in x]\n",
        "y2 = [lr_lambda_sin(i) for i in x]\n",
        "y3 = [transform_lr(i + 1) for i in x]\n",
        "\n",
        "# plt.plot(x, y1)\n",
        "# plt.plot(x, y2)\n",
        "# plt.plot(x, y3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Additive Margin Softmax Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class AMSoftmax(nn.Module):\n",
        "    # https://github.com/CoinCheung/pytorch-loss\n",
        "    def __init__(self,\n",
        "                 in_feats,\n",
        "                 n_classes=10,\n",
        "                 feat_norm=False,\n",
        "                 weight_norm=True,\n",
        "                 m=0.35,\n",
        "                 s=30):\n",
        "        super(AMSoftmax, self).__init__()\n",
        "        self.m = m\n",
        "        self.s = s\n",
        "        self.feat_norm = feat_norm\n",
        "        self.weight_norm = weight_norm\n",
        "        self.in_feats = in_feats\n",
        "        self.W = torch.nn.Parameter(torch.empty(in_feats, n_classes), requires_grad=True)\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        nn.init.xavier_normal_(self.W, gain=1)\n",
        "\n",
        "    def forward(self, x, lb):\n",
        "        assert x.size()[1] == self.in_feats\n",
        "        assert x.size()[0] == lb.size()[0]\n",
        "\n",
        "        if self.feat_norm:\n",
        "            x_norm = torch.norm(x, p=2, dim=1, keepdim=True).clamp(min=1e-9)\n",
        "            x = torch.div(x, x_norm)\n",
        "\n",
        "        if self.weight_norm:\n",
        "            w_norm = torch.norm(self.W, p=2, dim=0, keepdim=True).clamp(min=1e-9)\n",
        "            w = torch.div(self.W, w_norm)\n",
        "            costh = torch.mm(x, w)\n",
        "        else:\n",
        "            costh = torch.mm(x, self.W)\n",
        "\n",
        "        delt_costh = torch.zeros_like(costh).scatter_(1, lb.unsqueeze(1), self.m)\n",
        "        costh_m = costh - delt_costh\n",
        "        costh_m_s = self.s * costh_m\n",
        "        loss = self.ce(costh_m_s, lb)\n",
        "        return costh, loss\n",
        "    \n",
        "class ComformerAMSLoss2(nn.Module):\n",
        "    def __init__(self, *, comformer_v=1, m, ams_feat_norm, ams_weight_norm, ams_s, pred_layer, n_spks=600, d_model=80, **kargs):\n",
        "        super().__init__()\n",
        "        if comformer_v == 1:\n",
        "            self.comformer = Comformer(n_spks=n_spks, d_model=d_model, pred_layer=pred_layer, **kargs)\n",
        "        if comformer_v == 2:\n",
        "            self.comformer = Comformer2(n_spks=n_spks, d_model=d_model, pred_layer=pred_layer, **kargs)\n",
        "        self.amsLoss = AMSoftmax(d_model, n_spks, m=m, s=ams_s, feat_norm=ams_feat_norm, weight_norm=ams_weight_norm)\n",
        "        \n",
        "    def forward(self, mels, labels):\n",
        "        x = self.comformer(mels)\n",
        "        out, loss = self.amsLoss(x, labels)\n",
        "        return out, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class AngularPenaltySMLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, loss_type='arcface', eps=1e-7, s=None, m=None):\n",
        "        '''\n",
        "        Angular Penalty Softmax Loss\n",
        "\n",
        "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
        "        These losses are described in the following papers: \n",
        "        \n",
        "        ArcFace: https://arxiv.org/abs/1801.07698\n",
        "        SphereFace: https://arxiv.org/abs/1704.08063\n",
        "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
        "\n",
        "        '''\n",
        "        super(AngularPenaltySMLoss, self).__init__()\n",
        "        loss_type = loss_type.lower()\n",
        "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
        "        if loss_type == 'arcface':\n",
        "            self.s = 64.0 if not s else s\n",
        "            self.m = 0.5 if not m else m\n",
        "        if loss_type == 'sphereface':\n",
        "            self.s = 64.0 if not s else s\n",
        "            self.m = 1.35 if not m else m\n",
        "        if loss_type == 'cosface':\n",
        "            self.s = 30.0 if not s else s\n",
        "            self.m = 0.4 if not m else m\n",
        "        self.loss_type = loss_type\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        '''\n",
        "        input shape (N, in_features)\n",
        "        '''\n",
        "        assert len(x) == len(labels)\n",
        "        assert torch.min(labels) >= 0\n",
        "        assert torch.max(labels) < self.out_features\n",
        "        \n",
        "        for W in self.fc.parameters():\n",
        "            W = F.normalize(W, p=2, dim=1)\n",
        "\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "\n",
        "        wf = self.fc(x)\n",
        "        if self.loss_type == 'cosface':\n",
        "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
        "        if self.loss_type == 'arcface':\n",
        "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
        "        if self.loss_type == 'sphereface':\n",
        "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
        "\n",
        "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
        "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
        "        L = numerator - torch.log(denominator)\n",
        "        return wf, -torch.mean(L)\n",
        "    \n",
        "class ComformerAMSLoss(nn.Module):\n",
        "    def __init__(self, n_spks=600, d_model=80, loss_type='cosface', **kargs):\n",
        "        super().__init__()\n",
        "        self.comformer = Comformer(n_spks=n_spks, d_model=d_model, pred_layer=False, **kargs)\n",
        "        self.amsLoss = AngularPenaltySMLoss(d_model, n_spks, loss_type=loss_type)\n",
        "        \n",
        "    def forward(self, mels, labels):\n",
        "        x = self.comformer(mels)\n",
        "        out, loss = self.amsLoss(x, labels)\n",
        "        return out, loss\n",
        "\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-LN2XkteM_uH"
      },
      "source": [
        "# Model Function\n",
        "- Model forward function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N-rr8529JMz0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "\t\"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "\tmels, labels = batch\n",
        "\tmels = mels.to(device)\n",
        "\tlabels = labels.to(device)\n",
        "\n",
        "\touts = model(mels)\n",
        "\t# print(outs.shape)\n",
        "\t# print(outs[0])\n",
        "\t# print(labels.shape)\n",
        "\t# raise Exception\n",
        "\tloss = criterion(outs, labels)\n",
        "\n",
        "\t# Get the speaker id with highest probability.\n",
        "\tpreds = outs.argmax(1)\n",
        "\t# Compute accuracy.\n",
        "\taccuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "\treturn loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_ams_loss_fn(batch, model, device):\n",
        "\t\"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "\tmels, labels = batch\n",
        "\tmels = mels.to(device)\n",
        "\tlabels = labels.to(device)\n",
        "\n",
        "\touts, loss = model(mels, labels)\n",
        "\t# print(outs.shape)\n",
        "\t# print(outs[0])\n",
        "\t# print(labels.shape)\n",
        "\t# raise Exception\n",
        "\n",
        "\t# Get the speaker id with highest probability.\n",
        "\tpreds = outs.argmax(1)\n",
        "\t# Compute accuracy.\n",
        "\taccuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "\treturn loss, accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cwM_xyOtNCI2"
      },
      "source": [
        "# Validate\n",
        "- Calculate accuracy of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YAiv6kpdJRTJ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "def valid(dataloader, model, criterion, device): \n",
        "\t\"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "\tmodel.eval()\n",
        "\trunning_loss = 0.0\n",
        "\trunning_accuracy = 0.0\n",
        "\tpbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
        "\n",
        "\tfor i, batch in enumerate(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n",
        "\t\t\trunning_loss += loss.item()\n",
        "\t\t\trunning_accuracy += accuracy.item()\n",
        "\n",
        "\t\tpbar.update(dataloader.batch_size)\n",
        "\t\tpbar.set_postfix(\n",
        "\t\t\tloss=f\"{running_loss / (i+1):.2f}\",\n",
        "\t\t\taccuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "\t\t)\n",
        "\n",
        "\tpbar.close()\n",
        "\tmodel.train()\n",
        "\n",
        "\treturn (running_loss / len(dataloader), running_accuracy / len(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def valid_ams_loss(dataloader, model, device): \n",
        "\t\"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "\tmodel.eval()\n",
        "\trunning_loss = 0.0\n",
        "\trunning_accuracy = 0.0\n",
        "\tpbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
        "\n",
        "\tfor i, batch in enumerate(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tloss, accuracy = model_ams_loss_fn(batch, model, device)\n",
        "\t\t\trunning_loss += loss.item()\n",
        "\t\t\trunning_accuracy += accuracy.item()\n",
        "\n",
        "\t\tpbar.update(dataloader.batch_size)\n",
        "\t\tpbar.set_postfix(\n",
        "\t\t\tloss=f\"{running_loss / (i+1):.2f}\",\n",
        "\t\t\taccuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "\t\t)\n",
        "\n",
        "\tpbar.close()\n",
        "\tmodel.train()\n",
        "\n",
        "\treturn (running_loss / len(dataloader), running_accuracy / len(dataloader))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ne9G-eNEdG"
      },
      "source": [
        "# Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Usv9s-CuJSG7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "1846672\n",
            "1846672\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0% 0/2000 [00:00<?, ? step/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step_size = 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:22<00:00, 24.25 step/s, accuracy=0.00, loss=12.09, step=2000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2489.53 uttr/s, accuracy=0.01, loss=12.02]\n",
            "Train: 100% 2000/2000 [01:17<00:00, 25.68 step/s, accuracy=0.03, loss=11.09, step=4000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2603.63 uttr/s, accuracy=0.04, loss=11.15]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.68 step/s, accuracy=0.05, loss=10.58, step=6000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2641.76 uttr/s, accuracy=0.07, loss=10.58]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.62 step/s, accuracy=0.14, loss=9.73, step=8000] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2628.16 uttr/s, accuracy=0.11, loss=10.27]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.66 step/s, accuracy=0.22, loss=9.20, step=1e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2619.88 uttr/s, accuracy=0.17, loss=9.74]\n",
            "Train:   0% 4/2000 [00:00<06:59,  4.75 step/s, accuracy=0.11, loss=9.49, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10001, best model saved. (accuracy=0.1706)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:15<00:00, 26.32 step/s, accuracy=0.22, loss=9.28, step=12000] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2640.98 uttr/s, accuracy=0.19, loss=9.71]\n",
            "Train: 100% 2000/2000 [01:16<00:00, 26.26 step/s, accuracy=0.22, loss=9.19, step=14000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2591.50 uttr/s, accuracy=0.26, loss=8.96]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.57 step/s, accuracy=0.34, loss=8.57, step=16000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2632.26 uttr/s, accuracy=0.30, loss=8.68]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.64 step/s, accuracy=0.34, loss=7.92, step=18000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2599.34 uttr/s, accuracy=0.32, loss=8.49]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.65 step/s, accuracy=0.41, loss=7.97, step=2e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2603.10 uttr/s, accuracy=0.35, loss=8.23]\n",
            "Train:   0% 4/2000 [00:00<07:09,  4.65 step/s, accuracy=0.34, loss=8.11, step=2e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20001, best model saved. (accuracy=0.3457)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:17<00:00, 25.65 step/s, accuracy=0.41, loss=7.79, step=22000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2602.67 uttr/s, accuracy=0.41, loss=7.80]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.58 step/s, accuracy=0.45, loss=7.05, step=24000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2587.55 uttr/s, accuracy=0.43, loss=7.52]\n",
            "Train: 100% 2000/2000 [01:16<00:00, 26.11 step/s, accuracy=0.50, loss=6.94, step=26000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2794.77 uttr/s, accuracy=0.44, loss=7.38]\n",
            "Train: 100% 2000/2000 [01:12<00:00, 27.72 step/s, accuracy=0.44, loss=7.40, step=28000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2649.66 uttr/s, accuracy=0.47, loss=7.05]\n",
            "Train: 100% 2000/2000 [01:12<00:00, 27.73 step/s, accuracy=0.56, loss=6.52, step=3e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2772.29 uttr/s, accuracy=0.47, loss=7.02]\n",
            "Train:   0% 4/2000 [00:00<06:59,  4.76 step/s, accuracy=0.47, loss=6.71, step=3e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 30001, best model saved. (accuracy=0.4743)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:15<00:00, 26.63 step/s, accuracy=0.67, loss=5.41, step=32000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2714.76 uttr/s, accuracy=0.52, loss=6.59]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.11 step/s, accuracy=0.62, loss=5.77, step=34000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2729.59 uttr/s, accuracy=0.53, loss=6.43]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.06 step/s, accuracy=0.61, loss=5.73, step=36000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2721.56 uttr/s, accuracy=0.55, loss=6.23]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.06 step/s, accuracy=0.59, loss=5.28, step=38000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2708.93 uttr/s, accuracy=0.57, loss=5.95]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.79 step/s, accuracy=0.77, loss=4.44, step=4e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2715.73 uttr/s, accuracy=0.59, loss=5.75]\n",
            "Train:   0% 4/2000 [00:00<07:19,  4.54 step/s, accuracy=0.55, loss=6.03, step=4e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 40001, best model saved. (accuracy=0.5948)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:15<00:00, 26.63 step/s, accuracy=0.70, loss=4.90, step=42000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2733.88 uttr/s, accuracy=0.58, loss=5.87]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.21 step/s, accuracy=0.70, loss=4.17, step=44000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2698.94 uttr/s, accuracy=0.60, loss=5.59]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.29 step/s, accuracy=0.72, loss=4.52, step=46000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2733.05 uttr/s, accuracy=0.63, loss=5.20]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.18 step/s, accuracy=0.52, loss=5.60, step=48000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2689.01 uttr/s, accuracy=0.64, loss=5.17]\n",
            "Train: 100% 2000/2000 [01:17<00:00, 25.95 step/s, accuracy=0.72, loss=4.29, step=5e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2715.23 uttr/s, accuracy=0.64, loss=5.09]\n",
            "Train:   0% 2/2000 [00:00<07:49,  4.26 step/s, accuracy=0.70, loss=4.02, step=5e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 50001, best model saved. (accuracy=0.6438)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:14<00:00, 26.89 step/s, accuracy=0.70, loss=4.46, step=52000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2721.88 uttr/s, accuracy=0.65, loss=4.97]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.32 step/s, accuracy=0.64, loss=4.58, step=54000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2638.04 uttr/s, accuracy=0.67, loss=4.75]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.23 step/s, accuracy=0.77, loss=3.99, step=56000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2750.54 uttr/s, accuracy=0.68, loss=4.65]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.84 step/s, accuracy=0.77, loss=3.78, step=58000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2579.05 uttr/s, accuracy=0.68, loss=4.66]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.55 step/s, accuracy=0.78, loss=3.52, step=6e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2628.63 uttr/s, accuracy=0.69, loss=4.52]\n",
            "Train:   0% 2/2000 [00:00<07:31,  4.43 step/s, accuracy=0.80, loss=3.69, step=6e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60001, best model saved. (accuracy=0.6902)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:14<00:00, 27.00 step/s, accuracy=0.86, loss=3.22, step=62000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2736.59 uttr/s, accuracy=0.69, loss=4.46]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.30 step/s, accuracy=0.81, loss=3.43, step=64000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2750.32 uttr/s, accuracy=0.70, loss=4.37]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.09 step/s, accuracy=0.78, loss=3.47, step=66000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2792.92 uttr/s, accuracy=0.71, loss=4.16]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.46 step/s, accuracy=0.73, loss=3.70, step=68000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2749.25 uttr/s, accuracy=0.72, loss=4.11]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.91 step/s, accuracy=0.83, loss=2.70, step=7e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2630.09 uttr/s, accuracy=0.73, loss=4.03]\n",
            "Train:   0% 4/2000 [00:00<07:16,  4.57 step/s, accuracy=0.83, loss=2.99, step=7e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 70001, best model saved. (accuracy=0.7257)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:15<00:00, 26.57 step/s, accuracy=0.89, loss=2.43, step=72000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2719.24 uttr/s, accuracy=0.74, loss=3.89]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.73 step/s, accuracy=0.77, loss=3.44, step=74000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2722.75 uttr/s, accuracy=0.74, loss=3.87]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.09 step/s, accuracy=0.83, loss=2.76, step=76000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2659.25 uttr/s, accuracy=0.75, loss=3.70]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.91 step/s, accuracy=0.86, loss=2.47, step=78000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2736.56 uttr/s, accuracy=0.75, loss=3.78]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.84 step/s, accuracy=0.84, loss=2.03, step=8e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2717.57 uttr/s, accuracy=0.75, loss=3.73]\n",
            "Train:   0% 4/2000 [00:00<06:58,  4.77 step/s, accuracy=0.80, loss=2.82, step=8e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80001, best model saved. (accuracy=0.7507)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:14<00:00, 26.99 step/s, accuracy=0.88, loss=2.51, step=82000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2724.05 uttr/s, accuracy=0.75, loss=3.65]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.13 step/s, accuracy=0.83, loss=2.44, step=84000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2646.18 uttr/s, accuracy=0.76, loss=3.55]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.09 step/s, accuracy=0.89, loss=2.30, step=86000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2732.30 uttr/s, accuracy=0.76, loss=3.55]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.59 step/s, accuracy=0.84, loss=2.37, step=88000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2770.42 uttr/s, accuracy=0.77, loss=3.47]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.11 step/s, accuracy=0.94, loss=1.53, step=9e+4] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2757.71 uttr/s, accuracy=0.76, loss=3.51]\n",
            "Train:   0% 4/2000 [00:00<07:02,  4.72 step/s, accuracy=0.88, loss=2.44, step=9e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90001, best model saved. (accuracy=0.7697)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:13<00:00, 27.20 step/s, accuracy=0.83, loss=2.70, step=92000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2682.02 uttr/s, accuracy=0.78, loss=3.34]\n",
            "Train: 100% 2000/2000 [01:14<00:00, 26.95 step/s, accuracy=0.89, loss=1.93, step=94000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2737.41 uttr/s, accuracy=0.78, loss=3.33]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.44 step/s, accuracy=0.86, loss=2.50, step=96000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2432.96 uttr/s, accuracy=0.78, loss=3.34]\n",
            "Train: 100% 2000/2000 [01:15<00:00, 26.45 step/s, accuracy=0.86, loss=2.28, step=98000]\n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2692.39 uttr/s, accuracy=0.78, loss=3.33]\n",
            "Train: 100% 2000/2000 [01:13<00:00, 27.07 step/s, accuracy=0.83, loss=2.40, step=1e+5] \n",
            "Valid:  99% 5632/5667 [00:02<00:00, 2690.78 uttr/s, accuracy=0.78, loss=3.24]\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100001, best model saved. (accuracy=0.7837)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, RAdam, SGD\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"arguments\"\"\"\n",
        "    config = {\n",
        "        \"data_dir\": \"./Dataset\",\n",
        "        \"save_path\": \"model.ckpt\",\n",
        "        \"batch_size\": 64,\n",
        "        \"n_workers\": 8,\n",
        "        \"valid_steps\": 2000,\n",
        "        \"warmup_steps\": 7500,\n",
        "        \"sdg_step\": 50000,\n",
        "        \"save_steps\": 10000,\n",
        "        \"total_steps\": 100000,\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"comment\": \"d_model=100, nhead=4, comformer2_conv_2, drops, layers=12, self_attention_pooling_2, pred_layer_n=2, AMS_loss_2_with_norm, m=0.2, s=30, lr=0.001, milestone_sch_decay=0.85, batch_n=64, warmup_steps=7.5k, start_milestones=30k, total_steps=100k\"\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def main(\n",
        "    data_dir,\n",
        "    save_path,\n",
        "    batch_size,\n",
        "    n_workers,\n",
        "    valid_steps,\n",
        "    warmup_steps,\n",
        "    sdg_step,\n",
        "    total_steps,\n",
        "    save_steps,\n",
        "    learning_rate,\n",
        "    comment,\n",
        "):\n",
        "    writer = SummaryWriter(log_dir=f\"./runs/{comment}\")\n",
        "\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "    train_iterator = iter(train_loader)\n",
        "    print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "    # model = Classifier(d_model=240, nhead=6, encoder_layers=1, n_spks=speaker_num).to(device)\n",
        "    # model = ComformerAMSLoss(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "    model = ComformerAMSLoss2(comformer_v=2, m=0.2, ams_s=30, d_model=100, ams_weight_norm=True, ams_feat_norm=True, pred_layer=2, nhead=4, comformer_layers=12, n_spks=speaker_num, norm_after_cf_block=False).to(device)\n",
        "\n",
        "    # print(sum(p.numel() for p in model.parameters()))\n",
        "    # print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=240, num_attention_heads=6, num_encoder_layers=4).to(device)\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=64, num_attention_heads=1, num_encoder_layers=8).to(device)\n",
        "\n",
        "    print(sum(p.numel() for p in model.parameters()))\n",
        "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # return\n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    # criterion_validation = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    # optimizer = RAdam(model.parameters(), lr=1e-3)\n",
        "    # scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    # scheduler = get_transformer_scheduler(optimizer, warmup_steps)\n",
        "    scheduler = get_transformer_milestone_scheduler(optimizer, warmup_steps, 30000, min_lr=0.05, milestone_decay_rate=0.85, milestones=7500)\n",
        "    # scheduler = get_cosine_schedule(optimizer, total_steps)\n",
        "    # scheduler = get_exp_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    print(f\"[Info]: Finish creating model!\", flush = True)\n",
        "\n",
        "    best_accuracy = -1.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    grad_norm = []\n",
        "\n",
        "    step_size = batch_size // 32\n",
        "\n",
        "    print(f\"step_size = {step_size}\")\n",
        "\n",
        "    for step in range(total_steps // step_size):\n",
        "\n",
        "        step = (step + 1) * step_size\n",
        "\n",
        "        # if step == sdg_step:\n",
        "        # \toptimizer = SGD(model.parameters(), lr=scheduler.get_last_lr()[0], momentum=0.8, weight_decay=1e-5)\n",
        "        # \tscheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0)\n",
        "        # Get data\n",
        "        try:\n",
        "            batch = next(train_iterator)\n",
        "            # print(batch[0].shape)\n",
        "            # raise Exception\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)\n",
        "            batch = next(train_iterator)\n",
        "\n",
        "        # print(batch[0].shape)\n",
        "        # return\n",
        "        # loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "        loss, accuracy = model_ams_loss_fn(batch, model, device)\n",
        "        batch_loss = loss.item()\n",
        "        batch_accuracy = accuracy.item()\n",
        "\n",
        "        # Updata model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        for _ in range(step_size):\n",
        "            scheduler.step()\n",
        "\n",
        "        # if (step + 1)% 2000 == 0:\n",
        "        #     for name, param in model.named_parameters():\n",
        "        #         if param.requires_grad:\n",
        "        #             writer.add_histogram(f\"params/{name}\", param.detach(), step)\n",
        "\n",
        "\n",
        "        grad_norm.append(torch.max(torch.stack([p.grad.detach().abs().max() for p in model.parameters() if p.requires_grad])))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Log\n",
        "        for _ in range(step_size):\n",
        "            pbar.update()\n",
        "\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{batch_loss:.2f}\",\n",
        "            accuracy=f\"{batch_accuracy:.2f}\",\n",
        "            step=step,\n",
        "        )\n",
        "        train_loss.append(batch_loss)\n",
        "        train_acc.append(batch_accuracy)\n",
        "\n",
        "        # Do validation\t\t\n",
        "        if step % valid_steps == 0:\n",
        "            pbar.close()\n",
        "\n",
        "            # valid_loss, valid_accuracy = valid(valid_loader, model, criterion_validation, device)\n",
        "            valid_loss, valid_accuracy = valid_ams_loss(valid_loader, model, device)\n",
        "            writer.add_scalar(\"Accuracy/valid\", valid_accuracy, step)\n",
        "            writer.add_scalar(\"Loss/valid\", valid_loss, step)\n",
        "\n",
        "            # keep the best model\n",
        "            if valid_accuracy > best_accuracy:\n",
        "                best_accuracy = valid_accuracy\n",
        "                best_state_dict = model.state_dict()\n",
        "\n",
        "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "        # Save the best model so far.\n",
        "        if step % save_steps == 0 and best_state_dict is not None:\n",
        "            torch.save({\n",
        "                'step': step,\n",
        "                'model_state_dict': best_state_dict,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),    # HERE IS THE CHANGE\n",
        "                }, f\"{comment}.ckpt\")\n",
        "            # torch.save(best_state_dict, save_path)\n",
        "            pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            writer.add_scalar(\"Loss/train\", sum(train_loss) / len(train_loss), step)\n",
        "            writer.add_scalar(\"Accuracy/train\", sum(train_acc) / len(train_acc), step)\n",
        "            writer.add_scalar(\"Learning_rate\", scheduler.get_last_lr()[0], step)\n",
        "            train_loss = []\n",
        "            train_acc = []\n",
        "\n",
        "            for idx, gn in enumerate(grad_norm):\n",
        "                writer.add_scalar(\"GradNorm/train\", gn, step - (1000 - 1 - idx * step_size))\n",
        "\n",
        "            grad_norm = []\n",
        "\n",
        "    pbar.close()\n",
        "    writer.close()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# \tmain(**parse_args())\n",
        "\n",
        "config = parse_args()\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v1\"\n",
        "\n",
        "main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v2\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v3\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v4\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v5\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "4525216\n",
            "4525216\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:59<00:00, 16.67 step/s, accuracy=0.06, loss=19.19, step=2000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2051.96 uttr/s, accuracy=0.01, loss=18.81]\n",
            "Train: 100% 2000/2000 [02:05<00:00, 15.95 step/s, accuracy=0.03, loss=18.29, step=4000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1979.85 uttr/s, accuracy=0.04, loss=18.07]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.14 step/s, accuracy=0.09, loss=17.96, step=6000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2038.32 uttr/s, accuracy=0.07, loss=17.64]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.50 step/s, accuracy=0.12, loss=17.50, step=8000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2021.46 uttr/s, accuracy=0.09, loss=17.54]\n",
            "Train: 100% 2000/2000 [02:02<00:00, 16.38 step/s, accuracy=0.16, loss=16.72, step=1e+4]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2013.52 uttr/s, accuracy=0.17, loss=16.76]\n",
            "Train:   0% 1/2000 [00:00<10:41,  3.12 step/s, accuracy=0.16, loss=16.80, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10000, best model saved. (accuracy=0.1700)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.43 step/s, accuracy=0.22, loss=16.97, step=12000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1987.65 uttr/s, accuracy=0.20, loss=16.62]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.61 step/s, accuracy=0.19, loss=16.01, step=14000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1997.84 uttr/s, accuracy=0.25, loss=15.93]\n",
            "Train: 100% 2000/2000 [02:05<00:00, 15.88 step/s, accuracy=0.19, loss=16.22, step=16000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2023.97 uttr/s, accuracy=0.26, loss=16.10]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.75 step/s, accuracy=0.25, loss=15.87, step=18000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2028.46 uttr/s, accuracy=0.33, loss=15.30]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.57 step/s, accuracy=0.44, loss=14.37, step=2e+4] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1974.93 uttr/s, accuracy=0.36, loss=14.79]\n",
            "Train:   0% 1/2000 [00:00<09:46,  3.41 step/s, accuracy=0.47, loss=14.16, step=2e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20000, best model saved. (accuracy=0.3649)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:07<00:00, 15.72 step/s, accuracy=0.44, loss=14.03, step=22000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1999.65 uttr/s, accuracy=0.40, loss=14.39]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.56 step/s, accuracy=0.41, loss=13.05, step=24000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1998.95 uttr/s, accuracy=0.42, loss=14.20]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.52 step/s, accuracy=0.41, loss=12.92, step=26000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2001.14 uttr/s, accuracy=0.46, loss=13.47]\n",
            "Train: 100% 2000/2000 [02:06<00:00, 15.81 step/s, accuracy=0.62, loss=10.66, step=28000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2042.11 uttr/s, accuracy=0.49, loss=13.05]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.62 step/s, accuracy=0.44, loss=12.39, step=3e+4] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2026.73 uttr/s, accuracy=0.51, loss=12.74]\n",
            "Train:   0% 1/2000 [00:00<09:42,  3.43 step/s, accuracy=0.50, loss=12.95, step=3e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 30000, best model saved. (accuracy=0.5053)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:02<00:00, 16.34 step/s, accuracy=0.53, loss=12.79, step=32000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1959.42 uttr/s, accuracy=0.53, loss=12.45]\n",
            "Train: 100% 2000/2000 [02:09<00:00, 15.47 step/s, accuracy=0.50, loss=11.92, step=34000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2012.07 uttr/s, accuracy=0.53, loss=12.22]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.55 step/s, accuracy=0.62, loss=11.90, step=36000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2049.58 uttr/s, accuracy=0.58, loss=11.30]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.16 step/s, accuracy=0.72, loss=9.28, step=38000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2033.42 uttr/s, accuracy=0.60, loss=10.90]\n",
            "Train: 100% 2000/2000 [02:06<00:00, 15.83 step/s, accuracy=0.62, loss=9.72, step=4e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2038.24 uttr/s, accuracy=0.60, loss=10.91]\n",
            "Train:   0% 1/2000 [00:00<09:52,  3.37 step/s, accuracy=0.69, loss=10.23, step=4e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 40000, best model saved. (accuracy=0.6024)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.44 step/s, accuracy=0.78, loss=8.29, step=42000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2034.86 uttr/s, accuracy=0.64, loss=10.21]\n",
            "Train: 100% 2000/2000 [02:02<00:00, 16.30 step/s, accuracy=0.75, loss=9.23, step=44000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2024.59 uttr/s, accuracy=0.64, loss=10.04]\n",
            "Train: 100% 2000/2000 [02:04<00:00, 16.03 step/s, accuracy=0.84, loss=7.31, step=46000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2044.71 uttr/s, accuracy=0.66, loss=9.59]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.44 step/s, accuracy=0.75, loss=8.76, step=48000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2028.77 uttr/s, accuracy=0.66, loss=9.47]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.16 step/s, accuracy=0.75, loss=8.77, step=5e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1966.09 uttr/s, accuracy=0.68, loss=9.29]\n",
            "Train:   0% 1/2000 [00:00<11:24,  2.92 step/s, accuracy=0.72, loss=8.53, step=5e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 50000, best model saved. (accuracy=0.6811)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:03<00:00, 16.14 step/s, accuracy=0.88, loss=5.95, step=52000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2055.81 uttr/s, accuracy=0.68, loss=9.13]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.55 step/s, accuracy=0.75, loss=8.60, step=54000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2025.97 uttr/s, accuracy=0.68, loss=9.05]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.63 step/s, accuracy=0.66, loss=9.01, step=56000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2005.74 uttr/s, accuracy=0.70, loss=8.70]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.49 step/s, accuracy=0.69, loss=8.52, step=58000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2018.18 uttr/s, accuracy=0.70, loss=8.66]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.45 step/s, accuracy=0.59, loss=9.28, step=6e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1978.15 uttr/s, accuracy=0.72, loss=8.38]\n",
            "Train:   0% 1/2000 [00:00<09:57,  3.35 step/s, accuracy=0.84, loss=6.48, step=6e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60000, best model saved. (accuracy=0.7152)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:08<00:00, 15.58 step/s, accuracy=0.81, loss=6.79, step=62000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2022.21 uttr/s, accuracy=0.72, loss=8.28]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.58 step/s, accuracy=0.72, loss=9.41, step=64000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2037.93 uttr/s, accuracy=0.71, loss=8.39]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.43 step/s, accuracy=0.72, loss=9.06, step=66000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2069.85 uttr/s, accuracy=0.73, loss=8.09]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.69 step/s, accuracy=0.66, loss=8.47, step=68000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1933.04 uttr/s, accuracy=0.72, loss=8.23]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.43 step/s, accuracy=0.88, loss=5.94, step=7e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2020.68 uttr/s, accuracy=0.72, loss=8.20]\n",
            "Train:   0% 1/2000 [00:00<10:05,  3.30 step/s, accuracy=0.81, loss=6.88, step=7e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 70000, best model saved. (accuracy=0.7251)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.41 step/s, accuracy=0.81, loss=5.89, step=72000] \n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1826.06 uttr/s, accuracy=0.73, loss=8.04]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.68 step/s, accuracy=0.78, loss=6.63, step=74000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2015.87 uttr/s, accuracy=0.73, loss=8.07]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.43 step/s, accuracy=0.81, loss=7.68, step=76000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1992.84 uttr/s, accuracy=0.73, loss=7.91]\n",
            "Train: 100% 2000/2000 [02:06<00:00, 15.85 step/s, accuracy=0.91, loss=5.69, step=78000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1978.51 uttr/s, accuracy=0.73, loss=7.90]\n",
            "Train: 100% 2000/2000 [02:05<00:00, 15.92 step/s, accuracy=0.78, loss=6.73, step=8e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2006.91 uttr/s, accuracy=0.73, loss=8.01]\n",
            "Train:   0% 1/2000 [00:00<10:20,  3.22 step/s, accuracy=0.88, loss=4.78, step=8e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80000, best model saved. (accuracy=0.7327)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.46 step/s, accuracy=0.78, loss=5.91, step=82000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2050.54 uttr/s, accuracy=0.73, loss=7.90]\n",
            "Train: 100% 2000/2000 [02:02<00:00, 16.26 step/s, accuracy=0.75, loss=7.84, step=84000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1959.95 uttr/s, accuracy=0.73, loss=7.84]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.40 step/s, accuracy=0.88, loss=6.89, step=86000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2025.74 uttr/s, accuracy=0.74, loss=7.82]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.49 step/s, accuracy=0.94, loss=3.54, step=88000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1971.42 uttr/s, accuracy=0.73, loss=7.91]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.66 step/s, accuracy=0.81, loss=6.70, step=9e+4]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2037.36 uttr/s, accuracy=0.74, loss=7.76]\n",
            "Train:   0% 1/2000 [00:00<10:50,  3.07 step/s, accuracy=0.84, loss=6.73, step=9e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90000, best model saved. (accuracy=0.7385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:03<00:00, 16.22 step/s, accuracy=0.78, loss=5.97, step=92000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2039.44 uttr/s, accuracy=0.74, loss=7.75]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.50 step/s, accuracy=0.91, loss=4.44, step=94000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2031.95 uttr/s, accuracy=0.74, loss=7.79]\n",
            "Train: 100% 2000/2000 [02:06<00:00, 15.75 step/s, accuracy=0.75, loss=8.52, step=96000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1954.77 uttr/s, accuracy=0.73, loss=7.86]\n",
            "Train: 100% 2000/2000 [02:02<00:00, 16.28 step/s, accuracy=0.75, loss=7.20, step=98000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2024.08 uttr/s, accuracy=0.74, loss=7.85]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.54 step/s, accuracy=0.78, loss=6.89, step=1e+5]  \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2012.15 uttr/s, accuracy=0.73, loss=7.77]\n",
            "Train:   0% 1/2000 [00:00<10:11,  3.27 step/s, accuracy=0.81, loss=7.02, step=1e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100000, best model saved. (accuracy=0.7385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:04<00:00, 16.08 step/s, accuracy=0.75, loss=8.53, step=102000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2011.32 uttr/s, accuracy=0.74, loss=7.80]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.46 step/s, accuracy=0.84, loss=6.06, step=104000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2033.83 uttr/s, accuracy=0.73, loss=7.89]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.67 step/s, accuracy=0.81, loss=5.29, step=106000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2029.73 uttr/s, accuracy=0.73, loss=7.74]\n",
            "Train: 100% 2000/2000 [02:08<00:00, 15.58 step/s, accuracy=0.88, loss=5.85, step=108000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2028.16 uttr/s, accuracy=0.74, loss=7.69]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.42 step/s, accuracy=0.75, loss=8.08, step=110000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2018.79 uttr/s, accuracy=0.74, loss=7.74]\n",
            "Train:   0% 1/2000 [00:00<09:50,  3.39 step/s, accuracy=0.81, loss=6.86, step=110001]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 110000, best model saved. (accuracy=0.7385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:00<00:00, 16.56 step/s, accuracy=0.97, loss=6.17, step=112000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2016.26 uttr/s, accuracy=0.73, loss=7.69]\n",
            "Train: 100% 2000/2000 [02:07<00:00, 15.72 step/s, accuracy=0.84, loss=5.40, step=114000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2028.58 uttr/s, accuracy=0.74, loss=7.63]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.54 step/s, accuracy=0.72, loss=8.15, step=116000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2007.04 uttr/s, accuracy=0.74, loss=7.69]\n",
            "Train: 100% 2000/2000 [02:04<00:00, 16.10 step/s, accuracy=0.88, loss=5.95, step=118000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2031.04 uttr/s, accuracy=0.74, loss=7.63]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.14 step/s, accuracy=0.88, loss=6.19, step=120000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2045.04 uttr/s, accuracy=0.74, loss=7.76]\n",
            "Train:   0% 1/2000 [00:00<09:53,  3.37 step/s, accuracy=0.81, loss=5.97, step=120001]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 120000, best model saved. (accuracy=0.7442)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:00<00:00, 16.54 step/s, accuracy=0.72, loss=7.56, step=122000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2040.08 uttr/s, accuracy=0.75, loss=7.61]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.22 step/s, accuracy=0.88, loss=6.89, step=124000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2023.11 uttr/s, accuracy=0.73, loss=7.75]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.23 step/s, accuracy=0.81, loss=6.36, step=126000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1988.73 uttr/s, accuracy=0.73, loss=7.66]\n",
            "Train: 100% 2000/2000 [02:03<00:00, 16.14 step/s, accuracy=0.56, loss=10.07, step=128000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1913.14 uttr/s, accuracy=0.74, loss=7.60]\n",
            "Train: 100% 2000/2000 [02:06<00:00, 15.79 step/s, accuracy=0.78, loss=7.43, step=130000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1992.14 uttr/s, accuracy=0.74, loss=7.55]\n",
            "Train:   0% 1/2000 [00:00<12:12,  2.73 step/s, accuracy=0.81, loss=6.26, step=130001]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 130000, best model saved. (accuracy=0.7463)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.46 step/s, accuracy=0.78, loss=7.31, step=132000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2020.26 uttr/s, accuracy=0.74, loss=7.57]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.53 step/s, accuracy=0.88, loss=4.38, step=134000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1999.81 uttr/s, accuracy=0.74, loss=7.66]\n",
            "Train: 100% 2000/2000 [02:12<00:00, 15.13 step/s, accuracy=0.94, loss=4.96, step=136000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1983.25 uttr/s, accuracy=0.74, loss=7.55]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.45 step/s, accuracy=0.84, loss=4.90, step=138000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2019.17 uttr/s, accuracy=0.74, loss=7.58]\n",
            "Train: 100% 2000/2000 [02:00<00:00, 16.54 step/s, accuracy=0.81, loss=6.36, step=140000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2053.33 uttr/s, accuracy=0.74, loss=7.67]\n",
            "Train:   0% 1/2000 [00:00<09:45,  3.41 step/s, accuracy=0.81, loss=6.31, step=140001]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 140000, best model saved. (accuracy=0.7463)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:03<00:00, 16.20 step/s, accuracy=0.84, loss=6.31, step=142000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2016.00 uttr/s, accuracy=0.74, loss=7.61]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.47 step/s, accuracy=0.91, loss=4.14, step=144000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2027.33 uttr/s, accuracy=0.75, loss=7.49]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.45 step/s, accuracy=0.91, loss=5.05, step=146000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2049.94 uttr/s, accuracy=0.74, loss=7.53]\n",
            "Train: 100% 2000/2000 [02:05<00:00, 15.91 step/s, accuracy=0.69, loss=8.01, step=148000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2042.82 uttr/s, accuracy=0.74, loss=7.61]\n",
            "Train: 100% 2000/2000 [02:01<00:00, 16.40 step/s, accuracy=0.69, loss=7.66, step=150000] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2017.87 uttr/s, accuracy=0.75, loss=7.48]\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 150000, best model saved. (accuracy=0.7470)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, RAdam, SGD\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"arguments\"\"\"\n",
        "    config = {\n",
        "        \"data_dir\": \"./Dataset\",\n",
        "        \"save_path\": \"model.ckpt\",\n",
        "        \"batch_size\": 32,\n",
        "        \"n_workers\": 8,\n",
        "        \"valid_steps\": 2000,\n",
        "        \"warmup_steps\": 7500,\n",
        "        \"sdg_step\": 50000,\n",
        "        \"save_steps\": 10000,\n",
        "        \"total_steps\": 150000,\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"comment\": \"d_model=80, nhead=2, comformer2, drops, layers=16, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, s=40, lr=0.001, milestone_sch, warmup_steps=7.5k, start_milestones=35k, total_steps=150k\"\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def main(\n",
        "    data_dir,\n",
        "    save_path,\n",
        "    batch_size,\n",
        "    n_workers,\n",
        "    valid_steps,\n",
        "    warmup_steps,\n",
        "    sdg_step,\n",
        "    total_steps,\n",
        "    save_steps,\n",
        "    learning_rate,\n",
        "    comment,\n",
        "):\n",
        "    writer = SummaryWriter(log_dir=f\"./runs/{comment}\")\n",
        "\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "    train_iterator = iter(train_loader)\n",
        "    print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "    # model = Classifier(d_model=240, nhead=6, encoder_layers=1, n_spks=speaker_num).to(device)\n",
        "    # model = ComformerAMSLoss(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "    model = ComformerAMSLoss2(comformer_v=2, m=0.325, ams_s=40, d_model=80, ams_weight_norm=True, ams_feat_norm=True, pred_layer=False, nhead=2, comformer_layers=16, n_spks=speaker_num, norm_after_cf_block=False).to(device)\n",
        "\n",
        "    # print(sum(p.numel() for p in model.parameters()))\n",
        "    # print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=240, num_attention_heads=6, num_encoder_layers=4).to(device)\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=64, num_attention_heads=1, num_encoder_layers=8).to(device)\n",
        "\n",
        "    print(sum(p.numel() for p in model.parameters()))\n",
        "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # return\n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    # criterion_validation = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    # optimizer = RAdam(model.parameters(), lr=1e-3)\n",
        "    # scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    # scheduler = get_transformer_scheduler(optimizer, warmup_steps)\n",
        "    scheduler = get_transformer_milestone_scheduler(optimizer, warmup_steps, 35000)\n",
        "    # scheduler = get_cosine_schedule(optimizer, total_steps)\n",
        "    # scheduler = get_exp_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    print(f\"[Info]: Finish creating model!\", flush = True)\n",
        "\n",
        "    best_accuracy = -1.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    grad_norm = []\n",
        "\n",
        "    for step in range(total_steps):\n",
        "\n",
        "        # if step == sdg_step:\n",
        "        # \toptimizer = SGD(model.parameters(), lr=scheduler.get_last_lr()[0], momentum=0.8, weight_decay=1e-5)\n",
        "        # \tscheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0)\n",
        "        # Get data\n",
        "        try:\n",
        "            batch = next(train_iterator)\n",
        "            # print(batch[0].shape)\n",
        "            # raise Exception\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)\n",
        "            batch = next(train_iterator)\n",
        "\n",
        "        # print(batch[0].shape)\n",
        "        # return\n",
        "        # loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "        loss, accuracy = model_ams_loss_fn(batch, model, device)\n",
        "        batch_loss = loss.item()\n",
        "        batch_accuracy = accuracy.item()\n",
        "\n",
        "        # Updata model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # if (step + 1)% 2000 == 0:\n",
        "        #     for name, param in model.named_parameters():\n",
        "        #         if param.requires_grad:\n",
        "        #             writer.add_histogram(f\"params/{name}\", param.detach(), step)\n",
        "\n",
        "\n",
        "        grad_norm.append(torch.max(torch.stack([p.grad.detach().abs().max() for p in model.parameters() if p.requires_grad])))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Log\n",
        "        pbar.update()\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{batch_loss:.2f}\",\n",
        "            accuracy=f\"{batch_accuracy:.2f}\",\n",
        "            step=step + 1,\n",
        "        )\n",
        "        train_loss.append(batch_loss)\n",
        "        train_acc.append(batch_accuracy)\n",
        "\n",
        "        # Do validation\t\t\n",
        "        if (step + 1) % valid_steps == 0:\n",
        "            pbar.close()\n",
        "\n",
        "            # valid_loss, valid_accuracy = valid(valid_loader, model, criterion_validation, device)\n",
        "            valid_loss, valid_accuracy = valid_ams_loss(valid_loader, model, device)\n",
        "            writer.add_scalar(\"Accuracy/valid\", valid_accuracy, step)\n",
        "            writer.add_scalar(\"Loss/valid\", valid_loss, step)\n",
        "\n",
        "            # keep the best model\n",
        "            if valid_accuracy > best_accuracy:\n",
        "                best_accuracy = valid_accuracy\n",
        "                best_state_dict = model.state_dict()\n",
        "\n",
        "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "        # Save the best model so far.\n",
        "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "            torch.save({\n",
        "                'step': step + 1,\n",
        "                'model_state_dict': best_state_dict,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),    # HERE IS THE CHANGE\n",
        "                }, f\"{comment}.ckpt\")\n",
        "            # torch.save(best_state_dict, save_path)\n",
        "            pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "        if (step + 1) % 1000 == 0:\n",
        "            writer.add_scalar(\"Loss/train\", sum(train_loss) / len(train_loss), step)\n",
        "            writer.add_scalar(\"Accuracy/train\", sum(train_acc) / len(train_acc), step)\n",
        "            writer.add_scalar(\"Learning_rate\", scheduler.get_last_lr()[0], step)\n",
        "            train_loss = []\n",
        "            train_acc = []\n",
        "\n",
        "            for idx, gn in enumerate(grad_norm):\n",
        "                writer.add_scalar(\"GradNorm/train\", gn, step - (1000 - 1 - idx))\n",
        "\n",
        "            grad_norm = []\n",
        "\n",
        "    pbar.close()\n",
        "    writer.close()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# \tmain(**parse_args())\n",
        "\n",
        "config = parse_args()\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v1\"\n",
        "\n",
        "main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v2\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v3\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v4\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v5\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "7588272\n",
            "7588272\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:57<00:00, 17.06 step/s, accuracy=0.97, loss=2.04, step=72000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2005.48 uttr/s, accuracy=0.91, loss=3.45]\n",
            "Train: 100% 2000/2000 [01:53<00:00, 17.56 step/s, accuracy=0.91, loss=3.94, step=74000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2019.09 uttr/s, accuracy=0.91, loss=3.57]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.51 step/s, accuracy=0.81, loss=5.31, step=76000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1838.63 uttr/s, accuracy=0.90, loss=3.56]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.18 step/s, accuracy=1.00, loss=2.33, step=78000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2003.53 uttr/s, accuracy=0.90, loss=3.57]\n",
            "Train: 100% 2000/2000 [01:55<00:00, 17.37 step/s, accuracy=0.91, loss=3.99, step=8e+4] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2007.23 uttr/s, accuracy=0.91, loss=3.57]\n",
            "Train:   0% 1/2000 [00:00<13:26,  2.48 step/s, accuracy=0.97, loss=2.74, step=8e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80000, best model saved. (accuracy=0.9114)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:58<00:00, 16.85 step/s, accuracy=0.88, loss=3.28, step=82000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1870.57 uttr/s, accuracy=0.91, loss=3.47]\n",
            "Train: 100% 2000/2000 [01:58<00:00, 16.83 step/s, accuracy=0.78, loss=7.33, step=84000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2008.64 uttr/s, accuracy=0.90, loss=3.47]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.71 step/s, accuracy=0.94, loss=1.94, step=86000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2038.19 uttr/s, accuracy=0.91, loss=3.47]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.20 step/s, accuracy=0.94, loss=2.82, step=88000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1910.54 uttr/s, accuracy=0.90, loss=3.56]\n",
            "Train: 100% 2000/2000 [01:58<00:00, 16.93 step/s, accuracy=0.94, loss=3.58, step=9e+4] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1911.19 uttr/s, accuracy=0.90, loss=3.64]\n",
            "Train:   0% 1/2000 [00:00<10:50,  3.07 step/s, accuracy=0.91, loss=4.45, step=9e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90000, best model saved. (accuracy=0.9114)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:56<00:00, 17.16 step/s, accuracy=0.91, loss=2.93, step=92000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1963.05 uttr/s, accuracy=0.90, loss=3.56]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.53 step/s, accuracy=0.97, loss=2.54, step=94000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1973.83 uttr/s, accuracy=0.91, loss=3.54]\n",
            "Train: 100% 2000/2000 [01:57<00:00, 17.06 step/s, accuracy=0.94, loss=2.98, step=96000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1985.43 uttr/s, accuracy=0.91, loss=3.50]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.77 step/s, accuracy=0.88, loss=4.49, step=98000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2057.81 uttr/s, accuracy=0.91, loss=3.52]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.78 step/s, accuracy=0.84, loss=5.07, step=1e+5] \n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2001.79 uttr/s, accuracy=0.91, loss=3.53]\n",
            "Train:   0% 1/2000 [00:00<10:34,  3.15 step/s, accuracy=0.91, loss=4.61, step=1e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100000, best model saved. (accuracy=0.9114)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:58<00:00, 16.95 step/s, accuracy=1.00, loss=2.01, step=102000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 2001.89 uttr/s, accuracy=0.90, loss=3.52]\n",
            "Train: 100% 1993/2000 [01:55<00:00, 17.09 step/s, accuracy=0.91, loss=3.40, step=103993]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 193\u001b[0m\n\u001b[1;32m    189\u001b[0m config \u001b[39m=\u001b[39m parse_args()\n\u001b[1;32m    191\u001b[0m \u001b[39m# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v1\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m main(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m    195\u001b[0m \u001b[39m# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v2\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[39m# main(**config)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[39m# main(**config)\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[19], line 115\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_dir, batch_size, n_workers, valid_steps, warmup_steps, sdg_step, total_steps, save_steps, learning_rate, comment)\u001b[0m\n\u001b[1;32m    110\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(train_iterator)\n\u001b[1;32m    112\u001b[0m \u001b[39m# print(batch[0].shape)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# return\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# loss, accuracy = model_fn(batch, model, criterion, device)\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model_ams_loss_fn(batch, model, device)\n\u001b[1;32m    116\u001b[0m batch_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    117\u001b[0m batch_accuracy \u001b[39m=\u001b[39m accuracy\u001b[39m.\u001b[39mitem()\n",
            "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mmodel_ams_loss_fn\u001b[0;34m(batch, model, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m mels \u001b[39m=\u001b[39m mels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m outs, loss \u001b[39m=\u001b[39m model(mels, labels)\n\u001b[1;32m      9\u001b[0m \u001b[39m# print(outs.shape)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# print(outs[0])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(labels.shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# raise Exception\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m# Get the speaker id with highest probability.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m preds \u001b[39m=\u001b[39m outs\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[10], line 54\u001b[0m, in \u001b[0;36mComformerAMSLoss2.forward\u001b[0;34m(self, mels, labels)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, mels, labels):\n\u001b[0;32m---> 54\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomformer(mels)\n\u001b[1;32m     55\u001b[0m     out, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsLoss(x, labels)\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m out, loss\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[6], line 184\u001b[0m, in \u001b[0;36mComformer.forward\u001b[0;34m(self, mels)\u001b[0m\n\u001b[1;32m    182\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprenet(mels)\n\u001b[1;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 184\u001b[0m     out \u001b[39m=\u001b[39m layer(out)\n\u001b[1;32m    186\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(out)\n\u001b[1;32m    188\u001b[0m \u001b[39m# mean pooling\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# stats = out.mean(dim=1)\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[39m# self attention pooling\u001b[39;00m\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[6], line 113\u001b[0m, in \u001b[0;36mComformerBlock.forward\u001b[0;34m(self, mels)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39margs:\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m    mels: (batch size, length, 40)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    out: (batch size, n_spks)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m# out: (batch size, length, d_model)\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_1(mels)\n\u001b[1;32m    114\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(out)\n\u001b[1;32m    115\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(out)\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mResidualConnectionModule.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(inputs) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_factor) \u001b[39m+\u001b[39m (inputs \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_factor)\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mFeedForwardModule.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msequential(inputs)\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/side-projetcs/ML2022/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 1993/2000 [02:13<00:00, 17.09 step/s, accuracy=0.91, loss=3.40, step=103993]"
          ]
        }
      ],
      "source": [
        "# Resume\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, RAdam, SGD\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"arguments\"\"\"\n",
        "    config = {\n",
        "        \"data_dir\": \"./Dataset\",\n",
        "        \"batch_size\": 32,\n",
        "        \"n_workers\": 8,\n",
        "        \"valid_steps\": 2000,\n",
        "        \"warmup_steps\": 5000,\n",
        "        \"sdg_step\": 50000,\n",
        "        \"save_steps\": 10000,\n",
        "        \"total_steps\": 100000,\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"comment\": \"d_model=120, nhead=3, comformer, layers=12, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, s=40, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=100k, padding=1e-20\"\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def main(\n",
        "    data_dir,\n",
        "    batch_size,\n",
        "    n_workers,\n",
        "    valid_steps,\n",
        "    warmup_steps,\n",
        "    sdg_step,\n",
        "    total_steps,\n",
        "    save_steps,\n",
        "    learning_rate,\n",
        "    comment,\n",
        "):\n",
        "    writer = SummaryWriter(log_dir=f\"./runs/{comment}\")\n",
        "\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "    train_iterator = iter(train_loader)\n",
        "    print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "    # model = Classifier(d_model=240, nhead=6, encoder_layers=1, n_spks=speaker_num).to(device)\n",
        "    # model = ComformerAMSLoss(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "    model = ComformerAMSLoss2(m=0.325, ams_s=40, d_model=120, ams_weight_norm=True, ams_feat_norm=True, pred_layer=False, nhead=3, comformer_layers=12, n_spks=speaker_num, norm_after_cf_block=False).to(device)\n",
        "\n",
        "   \n",
        "    \n",
        "    # print(sum(p.numel() for p in model.parameters()))\n",
        "    # print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=240, num_attention_heads=6, num_encoder_layers=4).to(device)\n",
        "    # model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=64, num_attention_heads=1, num_encoder_layers=8).to(device)\n",
        "\n",
        "    print(sum(p.numel() for p in model.parameters()))\n",
        "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    # return\n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    # criterion_validation = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    # optimizer = RAdam(model.parameters(), lr=1e-3)\n",
        "    # scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    # scheduler = get_transformer_scheduler(optimizer, warmup_steps)\n",
        "    scheduler = get_transformer_milestone_scheduler(optimizer, warmup_steps, 35000, min_lr=0.001)\n",
        "    # scheduler = get_cosine_schedule(optimizer, total_steps)\n",
        "    # scheduler = get_exp_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    print(f\"[Info]: Finish creating model!\", flush = True)\n",
        "\n",
        "    checkpoint = torch.load(f\"{comment}.ckpt\")\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "\n",
        "    best_accuracy = -1.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    grad_norm = []\n",
        "\n",
        "    for step in range(checkpoint[\"step\"], total_steps):\n",
        "\n",
        "        # if step == sdg_step:\n",
        "        # \toptimizer = SGD(model.parameters(), lr=scheduler.get_last_lr()[0], momentum=0.8, weight_decay=1e-5)\n",
        "        # \tscheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0)\n",
        "        # Get data\n",
        "        try:\n",
        "            batch = next(train_iterator)\n",
        "            # print(batch[0].shape)\n",
        "            # raise Exception\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)\n",
        "            batch = next(train_iterator)\n",
        "\n",
        "        # print(batch[0].shape)\n",
        "        # return\n",
        "        # loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "        loss, accuracy = model_ams_loss_fn(batch, model, device)\n",
        "        batch_loss = loss.item()\n",
        "        batch_accuracy = accuracy.item()\n",
        "\n",
        "        # Updata model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # if (step + 1)% 2000 == 0:\n",
        "        #     for name, param in model.named_parameters():\n",
        "        #         if param.requires_grad:\n",
        "        #             writer.add_histogram(f\"params/{name}\", param.detach(), step)\n",
        "\n",
        "\n",
        "        grad_norm.append(torch.max(torch.stack([p.grad.detach().abs().max() for p in model.parameters() if p.requires_grad])))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Log\n",
        "        pbar.update()\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{batch_loss:.2f}\",\n",
        "            accuracy=f\"{batch_accuracy:.2f}\",\n",
        "            step=step + 1,\n",
        "        )\n",
        "        train_loss.append(batch_loss)\n",
        "        train_acc.append(batch_accuracy)\n",
        "\n",
        "        # Do validation\t\t\n",
        "        if (step + 1) % valid_steps == 0:\n",
        "            pbar.close()\n",
        "\n",
        "            # valid_loss, valid_accuracy = valid(valid_loader, model, criterion_validation, device)\n",
        "            valid_loss, valid_accuracy = valid_ams_loss(valid_loader, model, device)\n",
        "            writer.add_scalar(\"Accuracy/valid\", valid_accuracy, step)\n",
        "            writer.add_scalar(\"Loss/valid\", valid_loss, step)\n",
        "\n",
        "            # keep the best model\n",
        "            if valid_accuracy > best_accuracy:\n",
        "                best_accuracy = valid_accuracy\n",
        "                best_state_dict = model.state_dict()\n",
        "\n",
        "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "        # Save the best model so far.\n",
        "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "            torch.save({\n",
        "                'step': step + 1,\n",
        "                'model_state_dict': best_state_dict,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),    # HERE IS THE CHANGE\n",
        "                }, f\"{comment}-cont.ckpt\")\n",
        "            # torch.save(best_state_dict, save_path)\n",
        "            pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "        if (step + 1) % 1000 == 0:\n",
        "            writer.add_scalar(\"Loss/train\", sum(train_loss) / len(train_loss), step)\n",
        "            writer.add_scalar(\"Accuracy/train\", sum(train_acc) / len(train_acc), step)\n",
        "            writer.add_scalar(\"Learning_rate\", scheduler.get_last_lr()[0], step)\n",
        "            train_loss = []\n",
        "            train_acc = []\n",
        "\n",
        "            for idx, gn in enumerate(grad_norm):\n",
        "                writer.add_scalar(\"GradNorm/train\", gn, step - (1000 - 1 - idx))\n",
        "\n",
        "            grad_norm = []\n",
        "\n",
        "    pbar.close()\n",
        "    writer.close()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# \tmain(**parse_args())\n",
        "\n",
        "config = parse_args()\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v1\"\n",
        "\n",
        "main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v2\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v3\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v4\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "# config[\"comment\"] = \"d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v5\"\n",
        "\n",
        "# main(**config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NLatBYAhNNMx"
      },
      "source": [
        "# Inference\n",
        "\n",
        "## Dataset of inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "efS4pCmAJXJH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "\tdef __init__(self, data_dir, segment_len=None):\n",
        "\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n",
        "\t\tmetadata = json.load(testdata_path.open())\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.data = metadata[\"utterances\"]\n",
        "\t\tself.segment_len = segment_len\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tutterance = self.data[index]\n",
        "\t\tfeat_path = utterance[\"feature_path\"]\n",
        "\t\tmel = torch.load(os.path.join(self.data_dir, \"uttrs\", feat_path))\n",
        "\n",
        "\t\t# Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "\t\tif self.segment_len:\n",
        "\t\t\tif len(mel) > self.segment_len:\n",
        "\t\t\t\t# Randomly get the starting point of the segment.\n",
        "\t\t\t\tstart = random.randint(0, len(mel) - self.segment_len)\n",
        "\t\t\t\t# Get a segment with \"segment_len\" frames.\n",
        "\t\t\t\tmel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "\t\t\telse:\n",
        "\t\t\t\tmel = torch.FloatTensor(mel)\n",
        "\n",
        "\t\treturn feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "\t\"\"\"Collate a batch of data.\"\"\"\n",
        "\tfeat_paths, mels = zip(*batch)\n",
        "\tmels = pad_sequence(mels, batch_first=True, padding_value=1e-20)\n",
        "\n",
        "\treturn feat_paths, mels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0WnYwxNK_S"
      },
      "source": [
        "## Main funcrion of Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i8SAbuXEJb2A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/125 [00:00<?, ?it/s]/tmp/ipykernel_1413/798921256.py:142: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  att_w = softmax(self.W(batch_rep).squeeze(-1)).unsqueeze(-1)\n",
            "100%|██████████| 125/125 [00:02<00:00, 45.15it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 44.20it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 46.93it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 45.96it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 44.37it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.21it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.68it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.88it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.76it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.36it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.44it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.08it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.39it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.28it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.87it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.08it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.04it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.19it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.89it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.06it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.00it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.11it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.02it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.90it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.12it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.10it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.22it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.12it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.10it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.28it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.11it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.28it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.32it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.32it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.24it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.55it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.27it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.28it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.35it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.56it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.42it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.12it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.90it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 46.59it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 47.54it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.29it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.34it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.46it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.11it/s]\n",
            "100%|██████████| 125/125 [00:02<00:00, 48.06it/s]\n"
          ]
        }
      ],
      "source": [
        "# Small Segment Inference\n",
        "\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "from conformer import Conformer as RealComformer\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"./Dataset\",\n",
        "\t\t\"model_path\": \"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_2_with_nn_linear, AMS_loss_2, m=0.2, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=100k, padding=1e-20, total_steps=100k, padding=1e-20.ckpt\",\n",
        "\t\t\"output_path\": \"./output.csv\",\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tmodel_path,\n",
        "\toutput_path,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\tmapping = json.load(mapping_path.open())\n",
        "\n",
        "\tdataset = InferenceDataset(data_dir, segment_len=128)\n",
        "\tdataloader = DataLoader(\n",
        "\t\tdataset,\n",
        "\t\tbatch_size=64,\n",
        "\t\tshuffle=False,\n",
        "\t\tdrop_last=False,\n",
        "\t\tnum_workers=4,\n",
        "\t\tcollate_fn=inference_collate_batch,\n",
        "\t\tpin_memory=True\n",
        "\t)\n",
        "\tprint(f\"[Info]: Finish loading data!\", flush = True)\n",
        "\n",
        "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
        "\t# model = Comformer(d_model=144, nhead=4, comformer_layers=8, n_spks=speaker_num).to(device)\n",
        "\t# model = Comformer(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\tmodel = ComformerAMSLoss2(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\t# model = ComformerAMSLoss2(m=0.2, d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\n",
        "\n",
        "\t# model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=240, num_attention_heads=6, num_encoder_layers=4).to(device)\n",
        "\tmodel.load_state_dict(torch.load(model_path)[\"model_state_dict\"])\n",
        "\tmodel.eval()\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\t# results = []\n",
        "\tpredictions = defaultdict(list)\n",
        "\n",
        "\n",
        "\tfor _ in range(50):\n",
        "\t\tfor feat_paths, mels in tqdm(dataloader):\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tmels = mels.to(device)\n",
        "\t\t\t\tdummy_label = torch.zeros((64,)).long().to(device)\n",
        "\t\t\t\t# outs = model(mels)\n",
        "\t\t\t\touts, _ = model(mels, dummy_label)\n",
        "\t\t\t\touts = outs.cpu().numpy()\n",
        "\t\t\t\tfor feat_path, outs in zip(feat_paths, outs):\n",
        "\t\t\t\t\tpredictions[feat_path].append(outs)\n",
        "\t\n",
        "\tresults = []\n",
        "\tfor key, value in predictions.items():\n",
        "\t\tarr = np.array(value)\n",
        "\t\t# print(key)\n",
        "\t\t# print(arr)\n",
        "\t\t# print(arr.shape)\n",
        "\t\tvoting_res = arr.sum(axis=0)\n",
        "\t\t# print(voting_res.shape)\n",
        "\t\tvoting_res = voting_res.argmax()\n",
        "\t\t# print(voting_res.shape)\n",
        "\t\t# return\n",
        "\t\tresults.append((key, mapping[\"id2speaker\"][str(voting_res)]))\n",
        "\t\t\n",
        "\tresults.insert(0, (\"Id\", \"Category\"))\n",
        "\n",
        "\twith open(output_path, 'w', newline='') as csvfile:\n",
        "\t\twriter = csv.writer(csvfile)\n",
        "\t\twriter.writerows(results)\n",
        "\n",
        "\n",
        "\n",
        "main(**parse_args())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "Creating model with m=0.30000000000000004...\n",
            "[Info]: Finish creating model! Path:./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:37<00:00, 211.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating model with m=0.30000000000000004...\n",
            "[Info]: Finish creating model! Path:./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v2.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:37<00:00, 211.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating model with m=0.30000000000000004...\n",
            "[Info]: Finish creating model! Path:./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v3.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:37<00:00, 211.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating model with m=0.30000000000000004...\n",
            "[Info]: Finish creating model! Path:./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v4.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:38<00:00, 205.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating model with m=0.30000000000000004...\n",
            "[Info]: Finish creating model! Path:./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v6.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:38<00:00, 207.73it/s]\n"
          ]
        }
      ],
      "source": [
        "# Ensemble\n",
        "\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from conformer import Conformer as RealComformer\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"./Dataset\",\n",
        "\t\t\"model_paths\": [\n",
        "\t\t\t\"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20.ckpt\",\n",
        "\t\t\t\"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v2.ckpt\",\n",
        "\t\t\t\"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v3.ckpt\",\n",
        "\t\t\t\"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v4.ckpt\",\n",
        "\t\t\t\"./d_model=240, nhead=6, comformer, comformer_layers=4, self_attention_pooling_xavier_uniform_init, AMS_loss_2, m=0.3, no_pred_layer, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, total_steps=70k, padding=1e-20, v6.ckpt\",\n",
        "\t\t],\n",
        "\t\t\"output_path\": \"./output.csv\",\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tmodel_paths,\n",
        "\toutput_path,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\tmapping = json.load(mapping_path.open())\n",
        "\n",
        "\tdataset = InferenceDataset(data_dir)\n",
        "\tdataloader = DataLoader(\n",
        "\t\tdataset,\n",
        "\t\tbatch_size=1,\n",
        "\t\tshuffle=False,\n",
        "\t\tdrop_last=False,\n",
        "\t\t# num_workers=1,\n",
        "\t\tcollate_fn=inference_collate_batch,\n",
        "\t\tpin_memory=True\n",
        "\t)\n",
        "\tprint(f\"[Info]: Finish loading data!\", flush = True)\n",
        "\n",
        "\n",
        "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
        "\t# model = Comformer(d_model=144, nhead=4, comformer_layers=8, n_spks=speaker_num).to(device)\n",
        "\t# model = Comformer(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\t# model = ComformerAMSLoss2(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\t# model = ComformerAMSLoss2(m=0.2, d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\n",
        "\tpredictions = defaultdict(list)\n",
        "\n",
        "\tp = re.compile(r\", m=0.(\\d)\")\n",
        "\n",
        "\tfor model_path in model_paths:\n",
        "\t\tm = int(p.search(model_path).group(1)) * 0.1\n",
        "\t\tprint(f\"Creating model with m={m}...\")\n",
        "\t\tmodel = ComformerAMSLoss2(m=m, am_softmax_norm=True, pred_layer=False, d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num, norm_after_cf_block=False).to(device)\n",
        "\t\tmodel.load_state_dict(torch.load(model_path)[\"model_state_dict\"])\n",
        "\t\tmodel.eval()\n",
        "\t\tprint(f\"[Info]: Finish creating model! Path:{model_path}\", flush = True)\n",
        "\t\t\n",
        "\t\tfor feat_paths, mels in tqdm(dataloader):\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tmels = mels.to(device)\n",
        "\t\t\t\tdummy_label = torch.zeros((1,)).long().to(device)\n",
        "\t\t\t\t# outs = model(mels)\n",
        "\t\t\t\touts, _ = model(mels, dummy_label)\n",
        "\t\t\t\touts = torch.nn.functional.softmax(outs, dim=1).cpu().numpy()\n",
        "\t\t\t\t\n",
        "\t\t\tfor feat_path, outs in zip(feat_paths, outs):\n",
        "\t\t\t\tpredictions[feat_path].append(outs)\n",
        "\t\n",
        "\timport pickle \n",
        "\twith open('ensemble_outs.pkl', 'wb') as f:\n",
        "\t\tpickle.dump(predictions, f)\n",
        "\n",
        "\tresults = []\n",
        "\tfor feat_path, prediction in predictions.items():\n",
        "\t\tarr = np.array(prediction)\n",
        "\t\tvoting_res = arr.sum(axis=0).argmax()\n",
        "\t\tresults.append((feat_path, mapping[\"id2speaker\"][str(voting_res)]))\n",
        "\t\t\n",
        "\tresults.insert(0, (\"Id\", \"Category\"))\n",
        "\n",
        "\twith open(output_path, 'w', newline='') as csvfile:\n",
        "\t\twriter = csv.writer(csvfile)\n",
        "\t\twriter.writerows(results)\n",
        "\n",
        "main(**parse_args())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x300 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot\n",
        "\n",
        "import numpy as np\n",
        "import pickle \n",
        "with open('ensemble_outs.pkl', 'rb') as f:\n",
        "    predictions = pickle.load(f)\n",
        "\n",
        "model_paths = [\n",
        "    \"./d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v1.ckpt\",\n",
        "    \"./d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v2.ckpt\",\n",
        "    \"./d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v3.ckpt\",\n",
        "    \"./d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v4.ckpt\",\n",
        "    \"./d_model=240, nhead=6, comformer_with_layer_norm, layers=4, self_attention_pooling_2, no_pred_layer, AMS_loss_2_with_norm, m=0.325, lr=0.001, transformer_milestone_scheduler, warmup_steps=5k, start_milestones=35k, total_steps=70k, padding=1e-20, v5.ckpt\",\n",
        "]\n",
        "\n",
        "confidences = []\n",
        "for feat_path, prediction in predictions.items():\n",
        "    arr = np.array(prediction)\n",
        "    confs = np.amax(arr, axis=1)\n",
        "    conf = confs.sum() / confs.shape[0]\n",
        "    confidences.append((*confs, conf))\n",
        "    \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confidences = np.array(confidences).T\n",
        "\n",
        "fig, axs = plt.subplots(1, confidences.shape[0], sharey=True, figsize=(20, 3))\n",
        "\n",
        "# We can set the number of bins with the *bins* keyword argument.\n",
        "for idx, confidence in enumerate(confidences):\n",
        "    axs[idx].hist(confidence, bins=\"auto\")\n",
        "    if idx < len(model_paths):\n",
        "        axs[idx].set_title(model_paths[idx][-7:-5])\n",
        "    else:\n",
        "        axs[idx].set_title(\"sum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [01:33<00:00, 21.29it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Basic\n",
        "\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "from conformer import Conformer as RealComformer\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"./Dataset\",\n",
        "\t\t\"model_path\": \"./d_model=100, nhead=4, comformer2_conv_2, drops, layers=12, self_attention_pooling_2, pred_layer_n=2, AMS_loss_2_with_norm, m=0.2, s=30, lr=0.001, milestone_sch_decay=0.85, batch_n=64, warmup_steps=7.5k, start_milestones=30k, total_steps=100k.ckpt\",\n",
        "\t\t\"output_path\": \"./output.csv\",\n",
        "\t\t\"batch_size\": 4\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tmodel_path,\n",
        "\toutput_path,\n",
        "\tbatch_size\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\tmapping = json.load(mapping_path.open())\n",
        "\n",
        "\tdataset = InferenceDataset(data_dir)\n",
        "\tdataloader = DataLoader(\n",
        "\t\tdataset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tshuffle=False,\n",
        "\t\tdrop_last=False,\n",
        "\t\tnum_workers=4,\n",
        "\t\tcollate_fn=inference_collate_batch,\n",
        "\t)\n",
        "\tprint(f\"[Info]: Finish loading data!\", flush = True)\n",
        "\n",
        "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
        "\t# model = Comformer(d_model=144, nhead=4, comformer_layers=8, n_spks=speaker_num).to(device)\n",
        "\t# model = Comformer(d_model=240, nhead=6, comformer_layers=4, n_spks=speaker_num).to(device)\n",
        "\tmodel = ComformerAMSLoss2(comformer_v=2, m=0.2, ams_s=30, d_model=100, ams_weight_norm=True, ams_feat_norm=True, pred_layer=2, nhead=4, comformer_layers=12, n_spks=speaker_num, norm_after_cf_block=False).to(device)\n",
        "\n",
        "\n",
        "\t# model = RComformer(num_classes=speaker_num, input_dim=40, encoder_dim=240, num_attention_heads=6, num_encoder_layers=4).to(device)\n",
        "\tmodel.load_state_dict(torch.load(model_path)[\"model_state_dict\"])\n",
        "\tmodel.eval()\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\tresults = [[\"Id\", \"Category\"]]\n",
        "\tconfidence = []\n",
        "\tfor feat_paths, mels in tqdm(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tmels = mels.to(device)\n",
        "\t\t\tdummy_label = torch.zeros((batch_size,)).long().to(device)\n",
        "\t\t\t# outs = model(mels)\n",
        "\t\t\touts, _ = model(mels, dummy_label)\n",
        "\t\t\touts = nn.functional.softmax(outs, dim=1)\n",
        "\t\t\tpreds = outs.argmax(1).cpu().numpy()\n",
        "\t\t\tconfidences = outs.amax(1).cpu().numpy()\n",
        "\t\t\tfor feat_path, pred, conf in zip(feat_paths, preds, confidences):\n",
        "\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "\t\t\t\tconfidence.append(conf)\n",
        "\n",
        "\twith open(output_path, 'w', newline='') as csvfile:\n",
        "\t\twriter = csv.writer(csvfile)\n",
        "\t\twriter.writerows(results)\n",
        "\n",
        "\timport matplotlib.pyplot as plt\n",
        "\n",
        "\tfig, ax = plt.subplots(1, 1)\n",
        "\n",
        "\t# We can set the number of bins with the *bins* keyword argument.\n",
        "\tax.hist(confidence, bins=\"auto\")\n",
        "\n",
        "main(**parse_args())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
