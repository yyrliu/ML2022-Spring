{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jRDuJsGCgxCO"
   },
   "source": [
    "# HW3 Image Classification\n",
    "\n",
    "https://www.kaggle.com/c/ml2022spring-hw3b/code?competitionId=34954&sortBy=dateCreated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVgrPb3HhJUT"
   },
   "source": [
    "# Get Data\n",
    "Notes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "EAO6dg9eVaU_",
    "papermill": {
     "duration": 19.351342,
     "end_time": "2022-02-23T10:03:06.247288",
     "exception": false,
     "start_time": "2022-02-23T10:02:46.895946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip\n",
    "# ! wget -O food11.zip \"https://github.com/virginiakm1988/ML2022-Spring/blob/main/HW03/food11.zip?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HEsBm1lkhGmk",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! unzip food11.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f350fc0a9a0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "num_warmup_steps = 1000\n",
    "num_training_steps = 70000\n",
    "decay_const = 2.5\n",
    "\n",
    "def lr_lambda_exp(current_step):\n",
    "\t\t# Warmup\n",
    "\t\tif current_step < num_warmup_steps:\n",
    "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
    "\t\t# decadence\n",
    "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
    "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
    "\t\t)\n",
    "\t\treturn max(\n",
    "\t\t\t0.0, math.exp(-decay_const * progress)\n",
    "\t\t)\n",
    "\n",
    "num_cycles = 0.425\n",
    "\n",
    "def lr_lambda_sin(current_step):\n",
    "\t\t# Warmup\n",
    "\t\tif current_step < num_warmup_steps:\n",
    "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
    "\t\t# decadence\n",
    "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
    "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
    "\t\t)\n",
    "\t\treturn max(\n",
    "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "\t\t)\n",
    "\n",
    "switch_to_milestone_steps = 40000\n",
    "milestones = 5000\n",
    "milestones_decay = 0.7\n",
    "\n",
    "def transform_lr(current_step):\n",
    "\tif current_step < switch_to_milestone_steps:\n",
    "\t\tstep = current_step + 1\n",
    "\t\treturn min(step**(-0.5), step * num_warmup_steps**(-1.5)) / num_warmup_steps**(-0.5)\n",
    "\telse:\n",
    "\t\treturn switch_to_milestone_steps**(-0.5) / num_warmup_steps**(-0.5) * (milestones_decay ** ((current_step - switch_to_milestone_steps)//milestones + 1))\n",
    "\t    # return switch_to_milestone_steps**(-0.5)/ num_warmup_steps**(-0.5)\n",
    "\n",
    "\n",
    "x = [i for i in range(70000)]\n",
    "y1 = [lr_lambda_exp(i) for i in x]\n",
    "y2 = [lr_lambda_sin(i) for i in x]\n",
    "y3 = [transform_lr(i + 1) for i in x]\n",
    "\n",
    "# plt.plot(x, y1)\n",
    "# plt.plot(x, y2)\n",
    "plt.plot(x, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available\n",
      "One ./food11/training sample ./food11/training/0_0.jpg\n",
      "One ./food11/validation sample ./food11/validation/0_0.jpg\n",
      "One ./food11/validation sample ./food11/validation/0_0.jpg\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "#######################################################\n",
    "# Import necessary packages.\n",
    "#######################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_warmup as warmup\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset, IterableDataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "import signal, sys\n",
    "from contextlib import AbstractContextManager\n",
    "\n",
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "    print(\"Cuda is available\")\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Transforms (data augmentations)\n",
    "#######################################################\n",
    "\n",
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    \n",
    "    # You may add some transforms here.\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.01, 5)),\n",
    "    # transforms.RandomPerspective(distortion_scale=0.6, p=0.2),\n",
    "    # transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
    "    # transforms.RandomAutocontrast(p=0.2),\n",
    "    # transforms.RandomEqualize(p=0.2),\n",
    "\n",
    "    transforms.RandomChoice([\n",
    "        transforms.AutoAugment(policy) for policy in [\n",
    "            transforms.AutoAugmentPolicy.CIFAR10,\n",
    "            transforms.AutoAugmentPolicy.IMAGENET,\n",
    "            transforms.AutoAugmentPolicy.SVHN\n",
    "        ]\n",
    "    ]),\n",
    "    \n",
    "    # ToTensor() should be the last one of the transforms.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Dataset\n",
    "#######################################################\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,tfm=test_tfm,files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = np.array(sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")]))\n",
    "        if files != None:\n",
    "            self.files = np.array(files)\n",
    "        print(f\"One {path} sample\",self.files[0])\n",
    "        self.transform = tfm\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        #im = self.data[idx]\n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "        return im,label\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Network\n",
    "#######################################################\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "#######################################################\n",
    "# Dataloader\n",
    "#######################################################\n",
    "\n",
    "batch_size = 64\n",
    "_dataset_dir = \"./food11\"\n",
    "# Construct datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "valid_set_arg = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=train_tfm)\n",
    "valid_arg_loader = DataLoader(valid_set_arg, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Trainer\n",
    "#######################################################\n",
    "\n",
    "def train(loader, model, criterion, optimizer, scheduler, warmup_scheduler, device):\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_grad_norms = []\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    for imgs, labels in tqdm(loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        #imgs = imgs.half()\n",
    "        #print(imgs.shape,labels.shape)\n",
    "\n",
    "        # Forward the data. (Make sure data and model are on the same device.)\n",
    "        logits = model(imgs)\n",
    "\n",
    "        # Calculate the cross-entropy loss.\n",
    "        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norms for stable training.\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "        # Update the parameters with computed gradients.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = logits.argmax(dim=-1).eq_(labels).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_losses.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        train_grad_norms.append(grad_norm)\n",
    "        with warmup_scheduler.dampening():\n",
    "            pass\n",
    "\n",
    "    with warmup_scheduler.dampening():\n",
    "        scheduler.step()\n",
    "        \n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    train_grad_norm = sum(train_grad_norms) / len(train_grad_norms)\n",
    "\n",
    "    return train_loss, train_acc, train_grad_norm, lr\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Validation\n",
    "#######################################################\n",
    "\n",
    "def validate(loader, model, criterion, optimizer, device):\n",
    "    \n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for imgs, labels in tqdm(valid_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        #imgs = imgs.half()\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = logits.argmax(dim=-1).eq_(labels).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_losses.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_losses) / len(valid_losses)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    return valid_loss, valid_acc\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Logging\n",
    "#######################################################\n",
    "\n",
    "def log(msg, toFile=True):\n",
    "    global _exp_name\n",
    "    # print(msg)\n",
    "    if toFile:\n",
    "        with open(f\"./{_exp_name}.log\",\"a\") as f:\n",
    "            f.write(f\"{msg}\\n\")\n",
    "\n",
    "class TensorBoardWriter(AbstractContextManager):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        comment = kwargs.get(\"comment\", None)\n",
    "\n",
    "        if comment == \"test\" or comment is None:\n",
    "            self.writer = SummaryWriter(\"runs/test\")\n",
    "        else:\n",
    "            kwargs[\"comment\"] = f\"/{comment}\"\n",
    "            self.writer = SummaryWriter(*args, **kwargs)\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.writer\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(\"Closing TensorBoard writer...\")\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "model_resnet18 = resnet18(weights=None)\n",
    "model_resnet18.fc = nn.Sequential(\n",
    "    nn.Linear(512, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 11)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-layer-CNN-Res\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.cov = nn.Conv2d(dim, dim, 3, 1, 1, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.cov(x)\n",
    "        x = self.norm(x)\n",
    "        x = x + residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Convolutional(nn.Module):\n",
    "    # shape_in = (dim_in, H, W) -> shape_out = (dim_out, H/2, W/2)\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, 3, 1, 1, bias=False),    # [dim_out, H, W]\n",
    "            nn.BatchNorm2d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0)                   # [dim_out, H/2, W/2]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "        \n",
    "class Residual_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # input shape [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            Convolutional(3, 64),       # [64, 64, 64]\n",
    "            Residual(64),\n",
    "            Convolutional(64, 128),     # [128, 32, 32]\n",
    "            Residual(128),\n",
    "            Convolutional(128, 256),    # [256, 16, 16]\n",
    "            Residual(256),\n",
    "            Convolutional(256, 512),    # [512, 8, 8]\n",
    "            Convolutional(512, 512),    # [512, 4, 4]\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model_8_layer_rnn = Residual_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11-layer-CNN-Res\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.cov1 = nn.Conv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.cov2 = nn.Conv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm2 = nn.BatchNorm2d(dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.cov1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.cov2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = x + residual\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class Convolutional(nn.Module):\n",
    "    # shape_in = (dim_in, H, W) -> shape_out = (dim_out, H/2, W/2)\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, 3, 1, 1),    # [dim_out, H, W]\n",
    "            nn.BatchNorm2d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0)                   # [dim_out, H/2, W/2]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "        \n",
    "class Residual_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # input shape [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            Convolutional(3, 64),       # [64, 64, 64]\n",
    "            Residual(64),\n",
    "            Convolutional(64, 128),     # [128, 32, 32]\n",
    "            Residual(128),\n",
    "            Convolutional(128, 256),    # [256, 16, 16]\n",
    "            Residual(256),\n",
    "            Convolutional(256, 512),    # [512, 8, 8]\n",
    "            Convolutional(512, 512),    # [512, 4, 4]\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model = Residual_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=11, bias=True)\n",
      "  )\n",
      ")\n",
      "12232267 parameters, 12232267 trainable.\n"
     ]
    }
   ],
   "source": [
    "# Print network summary\n",
    "\n",
    "model_to_print = model_resnet18\n",
    "\n",
    "print(model_to_print)\n",
    "total_params = sum(p.numel() for p in model_to_print.parameters())\n",
    "total_params_trainable = sum(p.numel() for p in model_to_print.parameters() if p.requires_grad)\n",
    "print(f\"{total_params} parameters, {total_params_trainable} trainable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13296 13295\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation - Ensemble\n",
    "\n",
    "sets_num = 5\n",
    "\n",
    "labeled_set = ConcatDataset([train_set, valid_set])\n",
    "\n",
    "set_len = len(labeled_set)//5\n",
    "\n",
    "labeled_sets = [Subset(labeled_set, np.arange(set_len * i, set_len * i + 1)) for i in range(sets_num)]\n",
    "\n",
    "print(len(labeled_set), set_len*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def run(exp_name, model, n_epochs, patience=150, load_model=False, load_model_path=None, start_from_epoch=0, opti=\"Adam\", learning_rate=0.001, milestone_num=0):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    log(f\"\\n{datetime.datetime.now()} started new training...\\n\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    if load_model:\n",
    "        model_path = load_model_path or f\"{exp_name}.ckpt\"\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        log(f\"Continue with exsisted model '{model_path}'\")\n",
    "    else:\n",
    "        open(f\"./{exp_name}.log\", \"w\").close()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    if opti == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    elif opti == \"SGDM\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.8, weight_decay=1e-5)\n",
    "    \n",
    "    if milestone_num == 0:\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=n_epochs, gamma=1)\n",
    "    else:\n",
    "        milestone_epochs = n_epochs - start_from_epoch\n",
    "        milestones = list(range(milestone_epochs//milestone_num , milestone_epochs, milestone_epochs//milestone_num))\n",
    "        print(f\"Milestones: {milestones}\")\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.56)\n",
    "\n",
    "    if opti == \"Adam\":\n",
    "        warmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n",
    "    elif opti == \"SGDM\":\n",
    "        warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=155*10)\n",
    "\n",
    "    stale = 0\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    with TensorBoardWriter(comment=exp_name) as writer:\n",
    "        for epoch in range(start_from_epoch, n_epochs):\n",
    "            model.train()\n",
    "            train_loss, train_acc, train_grad_norm, lr = train(train_loader, model, criterion, optimizer, scheduler, warmup_scheduler, device)\n",
    "            log(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss, valid_acc = validate(valid_loader, model, criterion, optimizer, device)\n",
    "            log(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}{' -> best' if valid_acc > best_acc else ''}\")\n",
    "\n",
    "            writer.add_scalars('loss', {\n",
    "                    'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss,\n",
    "                }, epoch + 1)\n",
    "\n",
    "            writer.add_scalars('acc', {\n",
    "                    'train_acc': train_acc,\n",
    "                    'valid_acc': valid_acc,\n",
    "                }, epoch + 1)\n",
    "\n",
    "            writer.add_scalar('train_grad_norm', train_grad_norm, epoch + 1)\n",
    "            writer.add_scalar('learning_rate', lr, epoch + 1)\n",
    "\n",
    "            if valid_acc > best_acc:\n",
    "                log(f\"Best model so far, saving model\", toFile=False)\n",
    "                torch.save(model.state_dict(), f\"{exp_name}.ckpt\")\n",
    "                best_acc = valid_acc\n",
    "                best_epoch = epoch\n",
    "                stale = 0\n",
    "            else:\n",
    "                stale += 1\n",
    "                if stale > patience:\n",
    "                    log(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "                    break\n",
    "\n",
    "    print(f\"Best model found at epoch {best_epoch + 1:03d} of {n_epochs:03d}.\")\n",
    "\n",
    "    log(f\"{datetime.datetime.now()} finished training. Best model found at epoch {best_epoch + 1:03d} of {n_epochs:03d}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestones: [30, 60, 90, 120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:13<00:00, 11.17it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.67it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.53it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.57it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.39it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.75it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.25it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.00it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.80it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.09it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.96it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.70it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.31it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.98it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.30it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.83it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.92it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.93it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.36it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.81it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.49it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.78it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.52it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.47it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.07it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.82it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.87it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.58it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.97it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.71it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.96it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.03it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.05it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.32it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.00it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.96it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.15it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.26it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.23it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.98it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.40it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.93it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.64it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.81it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.87it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.62it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.95it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.97it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.93it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.52it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.99it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.24it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.03it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.27it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.95it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.60it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.38it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.87it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.43it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.97it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.48it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.89it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.73it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.94it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.16it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.89it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.09it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.69it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.94it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.34it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.93it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.31it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.38it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.43it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.90it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.23it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.96it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.99it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.70it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.95it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.58it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.92it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.91it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.66it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.94it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.39it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.69it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.85it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.69it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.35it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.00it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.95it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.63it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.05it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.04it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.28it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.91it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.16it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.31it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.95it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.60it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.03it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.23it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.96it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.18it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.58it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.00it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.70it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.80it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.04it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.58it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.94it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.09it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.03it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.08it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.94it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.75it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.91it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.94it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.10it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.99it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.60it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.08it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.00it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.62it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 16.43it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 11.96it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.60it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.30it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.88it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.87it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.10it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 17.90it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.03it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 20.20it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.01it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 16.63it/s]\n",
      "100%|██████████| 155/155 [00:12<00:00, 12.02it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.54it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.92it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.75it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.90it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 18.79it/s]\n",
      "100%|██████████| 155/155 [00:13<00:00, 11.87it/s]\n",
      "100%|██████████| 54/54 [00:02<00:00, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing TensorBoard writer...\n",
      "Best model found at epoch 340 of 450.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run(exp_name, model, n_epochs, patience=150, load_model=False, load_model_path=None, start_from_epoch=0, opti=\"Adam\")\n",
    "\n",
    "# _exp_name = \"auto_aug_re-8-layer-CNN_Res_LS_lr-warmup-scheduler_lr=0.00132_300\"\n",
    "# n_epochs = 300\n",
    "# config = {\n",
    "#     # \"patience\": 150, \n",
    "#     # \"load_model\": False,\n",
    "#     # \"load_model_path\": None,\n",
    "#     # \"start_from_epoch\": 0,\n",
    "#     \"opti\": \"Adam\",\n",
    "#     \"learning_rate\": 0.00132,\n",
    "#     \"milestone_num\": 10\n",
    "# }\n",
    "# run(_exp_name, model_8_layer_rnn, n_epochs, **config)\n",
    "\n",
    "\n",
    "_exp_name = \"auto_aug_re-8-layer-CNN_Res_LS_lr-warmup-scheduler_lr=0.00132_300_SDGM-lr=0.02\"\n",
    "# _exp_name = \"test\"\n",
    "n_epochs = 450\n",
    "\n",
    "config = {\n",
    "    \"patience\": 50, \n",
    "    \"load_model\": True,\n",
    "    \"load_model_path\": \"./auto_aug_re-8-layer-CNN_Res_LS_lr-warmup-scheduler_lr=0.00132_300.ckpt\",\n",
    "    \"start_from_epoch\": 300,\n",
    "    \"opti\": \"SGDM\",\n",
    "    \"learning_rate\": 0.0125,\n",
    "    \"milestone_num\": 5\n",
    "}\n",
    "\n",
    "run(_exp_name, model_8_layer_rnn, n_epochs, **config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbVkfIFhVaVO",
    "papermill": {
     "duration": 32830.720158,
     "end_time": "2022-02-23T19:10:19.001001",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.280843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_from_epoch = None\n",
    "load_model_path = None\n",
    "\n",
    "_exp_name = \"auto_aug_re-8-layer-CNN_Res_LS_SDGM-lr=0.01\"\n",
    "load_model = True\n",
    "load_model_path = \"./auto_aug_re-8-layer-CNN_Res_LS_best.ckpt\"\n",
    "start_from_epoch = 749\n",
    "\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "try:\n",
    "    writer = None\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "writer = SummaryWriter(comment=f\"/{_exp_name}\")\n",
    "\n",
    "# The number of training epochs and patience.\n",
    "n_epochs = 1000\n",
    "patience = 150 # If no improvement in 'patience' epochs, early stop\n",
    "\n",
    "log(f\"\\n{datetime.datetime.now()} started new training...\\n\")\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = model.to(device)\n",
    "\n",
    "if load_model:\n",
    "    model_path = load_model_path or f\"{_exp_name}_best.ckpt\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    log(f\"Continue with exsisted model '{model_path}'\")\n",
    "else:\n",
    "    open(f\"./{_exp_name}.log\", \"w\").close()\n",
    "\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8, weight_decay=1e-4) \n",
    "\n",
    "# Initialize trackers, these are not parameters and should not be changed\n",
    "stale = 0\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "start_from_epoch = start_from_epoch - 1 if start_from_epoch is not None else 0\n",
    "\n",
    "for epoch in range(start_from_epoch - 1, n_epochs):\n",
    "\n",
    "    # ---------- Training ----------\n",
    "    # Make sure the model is in train mode before training.\n",
    "    model.train()\n",
    "    train_loss, train_acc = train(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "    # Print the information.\n",
    "    log(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss, valid_acc = validate(valid_loader, model, criterion, optimizer, device)\n",
    "\n",
    "    # Print the information.\n",
    "    log(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}{' -> best' if valid_acc > best_acc else ''}\")\n",
    "\n",
    "    writer.add_scalars('status/loss', {\n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': valid_loss,\n",
    "        }, epoch + 1)\n",
    "\n",
    "    writer.add_scalars('status/acc', {\n",
    "            'train_acc': train_acc,\n",
    "            'valid_acc': valid_acc,\n",
    "        }, epoch + 1)\n",
    "\n",
    "    # save models\n",
    "    if valid_acc > best_acc:\n",
    "        log(f\"Best model so far, saving model\", toFile=False)\n",
    "        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "        best_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        stale = 0\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale > patience:\n",
    "            log(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break\n",
    "            \n",
    "print(f\"Best model found at epoch {best_epoch + 1:03d} of {n_epochs:03d}.\")   \n",
    "\n",
    "log(f\"{datetime.datetime.now()} finished training. Best model found at epoch {best_epoch + 1:03d} of {n_epochs:03d}.\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T13:12:03.273089Z",
     "iopub.status.busy": "2022-03-03T13:12:03.272682Z",
     "iopub.status.idle": "2022-03-03T13:12:03.288146Z",
     "shell.execute_reply": "2022-03-03T13:12:03.287465Z",
     "shell.execute_reply.started": "2022-03-03T13:12:03.273048Z"
    },
    "id": "B9QNdHIXVaVP",
    "papermill": {
     "duration": 0.493644,
     "end_time": "2022-02-23T19:10:19.985992",
     "exception": false,
     "start_time": "2022-02-23T19:10:19.492348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One ./food11/test sample ./food11/test/0001.jpg\n"
     ]
    }
   ],
   "source": [
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G31uyjpvVaVP",
    "papermill": {
     "duration": 0.498773,
     "end_time": "2022-02-23T19:10:20.961802",
     "exception": false,
     "start_time": "2022-02-23T19:10:20.463029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing and generate prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T13:12:03.290671Z",
     "iopub.status.busy": "2022-03-03T13:12:03.290214Z",
     "iopub.status.idle": "2022-03-03T13:12:37.20328Z",
     "shell.execute_reply": "2022-03-03T13:12:37.202502Z",
     "shell.execute_reply.started": "2022-03-03T13:12:03.290624Z"
    },
    "id": "bpLtxx5FVaVP",
    "papermill": {
     "duration": 49.157727,
     "end_time": "2022-02-23T19:11:10.61523",
     "exception": false,
     "start_time": "2022-02-23T19:10:21.457503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "_exp_name = \"auto_aug_re-8-layer-CNN_Res_LS_lr-warmup-scheduler_lr=0.00132_300\"\n",
    "model = model_8_layer_rnn\n",
    "\n",
    "model_best = model.to(device)\n",
    "# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}.ckpt\"))\n",
    "\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T13:12:37.204789Z",
     "iopub.status.busy": "2022-03-03T13:12:37.20452Z",
     "iopub.status.idle": "2022-03-03T13:12:37.235831Z",
     "shell.execute_reply": "2022-03-03T13:12:37.235207Z",
     "shell.execute_reply.started": "2022-03-03T13:12:37.204753Z"
    },
    "id": "fKupB3VUVaVQ",
    "papermill": {
     "duration": 0.554276,
     "end_time": "2022-02-23T19:11:11.870035",
     "exception": false,
     "start_time": "2022-02-23T19:11:11.315759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(f\"submission-{_exp_name}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivk0hrE-V8Cu"
   },
   "source": [
    "# Q1. Augmentation Implementation\n",
    "## Implement augmentation by finishing train_tfm in the code with image size of your choice. \n",
    "## Directly copy the following block and paste it on GradeScope after you finish the code\n",
    "### Your train_tfm must be capable of producing 5+ different results when given an identical image multiple times.\n",
    "### Your  train_tfm in the report can be different from train_tfm in your training code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSfKNo42WjKm"
   },
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    # You need to add some transforms here.\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HemRgZ6WwRM"
   },
   "source": [
    "# Q2. Residual Implementation\n",
    "![](https://i.imgur.com/GYsq1Ap.png)\n",
    "## Directly copy the following block and paste it on GradeScope after you finish the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4OK9kRaWuiV"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Residual_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Residual_Network, self).__init__()\n",
    "        \n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.cnn_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "\n",
    "        self.cnn_layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.cnn_layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.cnn_layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(256* 32* 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 11)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 128, 128]\n",
    "        # output: [batch_size, 11]\n",
    "\n",
    "        # Extract features by convolutional layers.\n",
    "        x1 = self.cnn_layer1(x)\n",
    "        \n",
    "        x1 = self.relu(x1)\n",
    "        \n",
    "        x2 = self.cnn_layer2(x1)\n",
    "        \n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x3 = self.cnn_layer3(x2)\n",
    "        \n",
    "        x3 = self.relu(x3)\n",
    "        \n",
    "        x4 = self.cnn_layer4(x3)\n",
    "        \n",
    "        x4 = self.relu(x4)\n",
    "        \n",
    "        x5 = self.cnn_layer5(x4)\n",
    "        \n",
    "        x5 = self.relu(x5)\n",
    "        \n",
    "        x6 = self.cnn_layer6(x5)\n",
    "        \n",
    "        x6 = self.relu(x6)\n",
    "        \n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        xout = x6.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        xout = self.fc_layer(xout)\n",
    "        return xout"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff100dc052e5191bb208904da00ff2d3dc290a004979977f4b045c374248fde1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
